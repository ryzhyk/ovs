import OVN_Northbound as nb
import OVN_Southbound as sb
import ovsdb
import allocate
import ovn

/* Meter_Band table */
for (mb in nb.Meter_Band) {
    sb.Out_Meter_Band(.uuid_name = uuid2str(mb._uuid),
                      .action = mb.action,
                      .rate = mb.rate,
                      .burst_size = mb.burst_size)
}

/* Meter table */
for (meter in nb.Meter) {
    sb.Out_Meter(.name = meter.name,
                 .unit = meter.unit,
                 .bands = set_map_uuid2str(meter.bands))
}

/* Datapath_Binding table */
sb.Out_Datapath_Binding(uuid_str, 0, external_ids) :-
    nb.Logical_Switch(._uuid = uuid, .name = name, .external_ids = ids),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids: Map<string, string> = map_empty();
        map_insert(eids, "logical-switch", uuid_str);
        map_insert(eids, "name", name);
        match (map_get(ids, "neutron:network_name")) {
            None -> (),
            Some{nnn} -> map_insert(eids, "name2", nnn)
        };
        eids
    }.

sb.Out_Datapath_Binding(uuid_str, 0, external_ids) :-
    nb.Logical_Router(._uuid = uuid, .name = name, .external_ids = ids),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids: Map<string, string> = map_empty();
        map_insert(eids, "logical-router", uuid_str);
        map_insert(eids, "name", name);
        match (map_get(ids, "neutron:router_name")) {
            None -> (),
            Some{nnn} -> map_insert(eids, "name2", nnn)
        };
        eids
    }.

sb.OutProxy_Datapath_Binding(uuid_str, tunkey, external_ids) :-
    sb.Out_Datapath_Binding(uuid_str, _, external_ids),
    TunKeyAllocation(uuid_str, tunkey).



/* Port_Binding table

relation Out_Port_Binding (
    uuid_name: string,
    logical_port: string,
    __type: string,
    gateway_chassis: Set<string>,
    options: Map<string,string>,
    datapath: string,
    tunnel_key: integer,
    parent_port: Set<string>,
    tag: Set<integer>,
    chassis: Set<uuid>,
    mac: Set<string>,
    nat_addresses: Set<string>,
    external_ids: Map<string,string>
)
*/

/* map logical ports to logical switches */
relation LogicalPortSwitch(lport: uuid, lswitch: uuid)

LogicalPortSwitch(lport, lswitch) :-
    nb.Logical_Switch(._uuid = lswitch, .ports = ports),
    var lport = FlatMap(ports).

relation LogicalPortRouter(lport: uuid, lrouter: uuid)

LogicalPortRouter(lport, lrouter) :-
    nb.Logical_Router(._uuid = lrouter, .ports = ports),
    var lport = FlatMap(ports).

/* Switch-to-router logical port connections */
relation SwitchRouterPeer(lsp: uuid, lrp: uuid)

SwitchRouterPeer(lsp, lrp) :-
    nb.Logical_Switch_Port(._uuid = lsp, .__type = "router", .options = options),
    Some{var router_port} = map_get(options, "router-port"),
    nb.Logical_Router_Port(.name = router_port, ._uuid = lrp).

/* Case 1: Create a Port_Binding per logical switch port that is not of type "router" */
sb.Out_Port_Binding(.uuid_name          = uuid_name,
                    .logical_port       = lsp.name,
                    .__type             = lsp.__type,
                    .gateway_chassis    = set_empty(),
                    .options            = lsp.options,
                    .datapath           = uuid2str(lswitch_uuid),
                    .tunnel_key         = 0,
                    .parent_port        = lsp.parent_name,
                    .tag                = set_empty(),
                    .mac                = lsp.addresses,
                    .nat_addresses      = set_empty(),
                    .external_ids       = eids) :-
    nb.Logical_Switch_Port[lsp],
    lsp.__type != "router",
    var uuid_name = uuid2str(lsp._uuid),
    LogicalPortSwitch(lsp._uuid, lswitch_uuid),
    var eids = {
        var eids = lsp.external_ids;
        match (map_get(lsp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    }.


/* Case 2: Create a Port_Binding per logical switch port of type "router" */
sb.Out_Port_Binding(.uuid_name          = uuid_name,
                    .logical_port       = lsp.name,
                    .__type             = __type,
                    .gateway_chassis    = set_empty(),
                    .options            = options,
                    .datapath           = uuid2str(lswitch_uuid),
                    .tunnel_key         = 0,
                    .parent_port        = lsp.parent_name,
                    .tag                = set_empty(),
                    .mac                = lsp.addresses,
                    .nat_addresses      = nat_addresses,
                    .external_ids       = eids) :-
    nb.Logical_Switch_Port[lsp],
    SwitchRouterPeer(.lsp = lsp._uuid, .lrp = lrp_uuid),
    var uuid_name = uuid2str(lsp._uuid),
    LogicalPortSwitch(lsp._uuid, lswitch_uuid),
    var eids = {
        var eids = lsp.external_ids;
        match (map_get(lsp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    },
    Some{var router_port} = map_get(lsp.options, "router-port"),
    LogicalPortRouter(lrp_uuid, lrouter_uuid),
    nb.Logical_Router(._uuid = lrouter_uuid, .options = lroptions),
    (var __type, var options, var nat_addresses) = {
        match (map_get(lroptions, "chassis")) {
            None -> {
                ("patch", map_empty(): Map<string, string>, set_empty(): Set<string>/*TODO*/)
            },
            Some{chassis} -> {
                var options: Map<string, string> = map_empty();
                map_insert(options, "peer", router_port);
                map_insert(options, "l3gateway-chassis", chassis);
                ("l3gateway", options, set_empty(): Set<string>/*TODO*/)
            }
        }
    }.

/* Case 3: Port_Binding per logical router port */
sb.Out_Port_Binding(.uuid_name          = uuid_name,
                    .logical_port       = lrp.name,
                    .__type             = __type,
                    .gateway_chassis    = set_empty(),
                    .options            = map_union(options1, options2),
                    .datapath           = uuid2str(lrouter_uuid),
                    .tunnel_key         = 0,
                    .parent_port        = set_empty(),
                    .tag                = set_empty(), // always empty for router ports
                    .mac                = set_singleton(set_space_sep(set_insert_imm(lrp.networks, lrp.mac))),
                    .nat_addresses      = set_empty(),
                    .external_ids       = lrp.external_ids) :-
    nb.Logical_Router_Port[lrp],
    var uuid_name = uuid2str(lrp._uuid),
    LogicalPortRouter(lrp._uuid, lrouter_uuid),
    nb.Logical_Router(._uuid = lrouter_uuid, .options = lroptions),
    (var __type, var options1) = match (map_get(lroptions, "chassis")) {
        /* TODO: derived ports */
        None -> ("patch", map_empty(): Map<string, string>),
        Some{lrchassis} -> ("l3gateway", map_singleton("l3gateway-chassis", lrchassis))
    },
    var options2 = match (map_get(lrp.options, "peer")) {
        None -> map_empty(): Map<string, string>,
        Some{peer} -> map_singleton("peer", peer)
    },
    var eids = {
        var eids = lrp.external_ids;
        match (map_get(lrp.external_ids, "neutron:port_name")) {
            None -> (),
            Some{name} -> map_insert(eids, "name", name)
        };
        eids
    }.

/*
 * Create derived port for Logical_Router_Ports with non-empty 'gateway_chassis' column.
 */

/* ChassisRedirectPort -- an intermediate table of router ports for which derived ports
   must be created in SB. */
relation ChassisRedirectPort(lrp: nb.Logical_Router_Port, lr_uuid: uuid)

ChassisRedirectPort(lrp1, lr._uuid) :-
    // For each router, find router ports with non-empty gateway_chassis or a "redirect-chassis" option.
    nb.Logical_Router[lr],
    LogicalPortRouter(lrp_uuid, lr._uuid),
    lrp in nb.Logical_Router_Port(._uuid = lrp_uuid),
        (not set_is_empty(lrp.gateway_chassis)) or map_contains_key(lrp.options, "redirect-chassis"),
    // if both gateway_chassis and options:redirect-chassis are present, log a warning and
    // ignore options:redirect-chassis.
    // (here we just log the warning; subsequent rules will ignore options:redirect-chassis)
    if ((not set_is_empty(lrp.gateway_chassis)) and map_contains_key(lrp.options, "redirect-chassis")) {
        warn($"logical router port ${lrp.name} has both options:" ++
              "redirect-chassis and gateway_chassis populated "   ++
              "redirect-chassis will be ignored in favour of gateway chassis");
        true
    } else { true },
    // It is an error if lrp.options:chassis exists.
    match (map_get(lrp.options, "chassis")) {
        Some{_} -> {
            warn("Bad configuration: redirect-chassis configured on port ${lrp.name} on L3 gateway router");
            false
        },
        _ -> true
    },
    // It is an error if a given Logical_Router has more than one such Logical_Router_Port.
    // If that happens, select an arbitrary one and log a warning.
    var lrps = Aggregate((lr), group2set(lrp)),
    Some{var lrp1: nb.Logical_Router_Port} = match (set_size(lrps)) {
        0 -> None,
        1 -> set_nth(lrps,0),
        _ -> {
            warn($"Bad configuration: multiple ports with redirect-chassis on same logical router ${lr.name}");
            set_nth(lrps,0)
        }
    }.

/* For each router port, tracks whether it's a redirect port of its router */
relation RouterPortIsRedirect(lrp: uuid, is_redirect: bool)

RouterPortIsRedirect(lrp, true) :- ChassisRedirectPort(nb.Logical_Router_Port{._uuid = lrp}, _).
RouterPortIsRedirect(lrp, false) :-
    nb.Logical_Router_Port(._uuid = lrp),
    not ChassisRedirectPort(nb.Logical_Router_Port{._uuid = lrp}, _).

function chassis_redirect_name(port_name: string): string = $"cr-${port_name}"

relation LogicalRouterHasRedirectPort(lr: uuid, has_redirect_port: bool)

LogicalRouterHasRedirectPort(lr, true) :-
    ChassisRedirectPort(_, lr).

LogicalRouterHasRedirectPort(lr, false) :-
    ChassisRedirectPort(_, lr).

/* Create derived ports */
sb.Out_Port_Binding(.uuid_name          = "cr" ++ uuid2str(lrp._uuid),
                    .logical_port       = lrp.name,
                    .__type             = "chassisredirect",
                    .gateway_chassis    = gateway_chassis,
                    .options            = map_singleton("distributed-port", chassis_redirect_name(lrp.name)),
                    .datapath           = uuid2str(lr_uuid),
                    .tunnel_key         = 0,
                    .parent_port        = set_empty(),
                    .tag                = set_empty(),  //always empty for router ports
                    .mac                = set_singleton(set_space_sep(set_insert_imm(lrp.networks, lrp.mac))),
                    .nat_addresses      = set_empty(),
                    .external_ids       = lrp.external_ids) :-
    ChassisRedirectPort(lrp, lr_uuid),
    var gateway_chassis = if (not set_is_empty(lrp.gateway_chassis)) {
        set_map_uuid2str(lrp.gateway_chassis)
    } else {
        set_singleton(uuid2str(lr_uuid))
    }.

/* Create sb.Gateway_Chassis for derived ports.
 * - For derived ports with non-empty gateway_chassis, clone nb.Gateway_Chassis to
 *   sb.Gateway_Chassis, replacing chassis_name's with matching sb.Chassis uuid's.
 * - For derived ports with options:redirect-chassis, synthesize a fresh Gateway_Chassis
 */
sb.Out_Gateway_Chassis(.uuid_name       = uuid2str(gateway_chassis_uuid),
                       .name            = gw_chassis.name,
                       .chassis         = set_singleton(chassis_uuid),
                       .priority        = gw_chassis.priority,
                       .external_ids    = gw_chassis.external_ids,
                       .options         = gw_chassis.options) :-
    ChassisRedirectPort(lrp, lr_uuid),
    var gateway_chassis_uuid = FlatMap(lrp.gateway_chassis),
    gw_chassis in nb.Gateway_Chassis(._uuid = gateway_chassis_uuid),
    sb.Chassis(._uuid = chassis_uuid, .name = gw_chassis.chassis_name).

sb.Out_Gateway_Chassis(.uuid_name       = uuid2str(lr_uuid),
                       .name            = $"${lrp.name}_${redirect_chassis}",
                       .chassis         = set_singleton(chassis_uuid),
                       .priority        = 0,
                       .external_ids    = lrp.external_ids,
                       .options         = map_empty()) :-
    ChassisRedirectPort(lrp, lr_uuid),
    set_is_empty(lrp.gateway_chassis),
    Some{var redirect_chassis} = map_get(lrp.options, "redirect-chassis"),
    sb.Chassis(._uuid = chassis_uuid, .name = redirect_chassis).

/* Add allocated qdisc_queue_id and tunnel key to Port_Binding.
 */
sb.OutProxy_Port_Binding(.uuid_name          = pbinding.uuid_name,
                         .logical_port       = pbinding.logical_port,
                         .__type             = pbinding.__type,
                         .gateway_chassis    = pbinding.gateway_chassis,
                         .options            = options,
                         .datapath           = pbinding.datapath,
                         .tunnel_key         = tunkey,
                         .parent_port        = pbinding.parent_port,
                         .tag                = pbinding.tag,
                         .mac                = pbinding.mac,
                         .nat_addresses      = pbinding.nat_addresses,
                         .external_ids       = pbinding.external_ids) :-
    sb.Swizzled_Port_Binding[pbinding],
    PortTunKeyAllocation(pbinding.uuid_name, tunkey),
    QueueIDAllocation(pbinding.uuid_name, qid),
    var options = match (qid) {
        None -> pbinding.options,
        Some{id} -> map_insert_imm(pbinding.options, "qdisc_queue_id", $"${id}")
    }.

/*
 * SB_Global copy nb_cfg and options from NB
 */
for (nb_global in nb.NB_Global) {
    sb.Out_SB_Global(.nb_cfg         = nb_global.nb_cfg,
                     .external_ids   = nb_global.external_ids,
                     .connections    = nb_global.connections,
                     .ssl            = nb_global.ssl,
                     .options        = nb_global.options,
                     .ipsec          = nb_global.ipsec)
}

/*
 * Address_Set: copy from NB + additional records generated from NB Port_Group (two records for each
 * Port_Group for IPv4 and IPv6 addresses).
 *
 * There can be name collisions between the two types of Address_Set records.  User-defined records
 * take precedence.
 */
for (nb_as in nb.Address_Set) {
    sb.Out_Address_Set(.name      = nb_as.name,
                       .addresses = nb_as.addresses)
}

/* PortStaticAddresses: static IP addresses associated with each Logical_Switch_Port */
relation PortStaticAddresses(lsport: uuid, ip4addrs: Set<string>, ip6addrs: Set<string>)

/* PortDynamicAddresses: dynamic IP addresses associated with each Logical_Switch_Port */
relation PortDynamicAddresses(lsport: uuid, ip4addrs: Set<string>, ip6addrs: Set<string>)

PortStaticAddresses(.lsport     = port_uuid,
                    .ip4addrs   = set_unions(ip4_addrs),
                    .ip6addrs   = set_unions(ip6_addrs)) :-
    nb.Logical_Switch_Port(._uuid = port_uuid, .addresses = addresses),
    var address = FlatMap(if set_is_empty(addresses) set_singleton("") else addresses),
    (var ip4addrs: Set<string>, var ip6addrs: Set<string>) = if (not is_dynamic_lsp_address(address)) {
        split_addresses(address)
    } else { (set_empty(), set_empty()) },
    var static_addrs = Aggregate((port_uuid), group_unzip((ip4addrs, ip6addrs))),
    (var ip4_addrs, var ip6_addrs) = static_addrs.

PortDynamicAddresses(.lsport     = port_uuid,
                     .ip4addrs   = set_unions(ip4_addrs),
                     .ip6addrs   = set_unions(ip6_addrs)) :-
    nb.Logical_Switch_Port(._uuid = port_uuid, .dynamic_addresses = addresses),
    var address = FlatMap(if set_is_empty(addresses) set_singleton("") else addresses),
    (var ip4_addrs, var ip6_addrs) = split_addresses(address),
    var dyn_addrs = Aggregate((port_uuid), group_unzip((ip4_addrs, ip6_addrs))),
    (var ip4_addrs, var ip6_addrs) = dyn_addrs.


sb.Out_Address_Set(as_name, set_unions(pg_ip4addrs)) :-
    nb.Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip4addrs = stat),
    PortDynamicAddresses(.lsport = port_uuid, .ip4addrs = dynamic),
    var port_ip4addrs: Set<string> = set_union(stat, dynamic),
    var pg_ip4addrs = Aggregate((as_name), group2vec(port_ip4addrs)).

sb.Out_Address_Set(as_name, set_empty()) :-
    nb.Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name).

sb.Out_Address_Set(as_name, set_unions(pg_ip6addrs)) :-
    nb.Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip6addrs = stat),
    PortDynamicAddresses(.lsport = port_uuid, .ip6addrs = dynamic),
    var port_ip6addrs = set_union(stat, dynamic),
    var pg_ip6addrs = Aggregate((as_name), group2vec(port_ip6addrs)).

sb.Out_Address_Set(as_name, set_empty()) :-
    nb.Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb.Address_Set(.name = as_name).


/*
 * Port_Group: copy from NB, but replace UUIDs with logical port names
 */
sb.Out_Port_Group(.name = pg_name, .ports = port_names) :-
    nb.Port_Group(.name = pg_name, .ports = pg_ports),
    var port_uuid = FlatMap(pg_ports),
    nb.Logical_Switch_Port(._uuid = port_uuid, .name = port_name),
    var port_names = Aggregate((pg_name), group2set(port_name)).

sb.Out_Port_Group(.name = pg_name, .ports = set_empty()) :-
    nb.Port_Group(.name = pg_name, .ports = set_empty()).


/*
 * Multicast_Group: two rows per logical switch, one for flooding and one for packets with unknown
 * destinations.
 */

function mC_FLOOD(): string   = "_MC_flood"
function mC_UNKNOWN(): string = "_MC_unknown"

// TODO: check that Multicast_Group.ports should not include derived ports

/* Logical switches that have enabled ports with "unknown" address */
relation LogicalSwitchUnknownPorts(ls: uuid, port_ids: Set<uuid>)

LogicalSwitchUnknownPorts(ls, port_ids) :-
    nb.Logical_Switch(._uuid = ls, .ports = ports),
    var port_id = FlatMap(ports),
    nb.Logical_Switch_Port(._uuid = port_id, .enabled = enabled, .addresses = addresses),
    is_enabled(enabled) and set_contains(addresses, "unknown"),
    var port_ids = Aggregate((ls), group2set(port_id)).

/* Only create flood group if the switch has enabled ports */
sb.Out_Multicast_Group (.datapath   = datapath,
                        .name       = mC_FLOOD(),
                        .tunnel_key = 65535,
                        .ports      = set_map_uuid2str(port_ids)) :-
    nb.Logical_Switch[ls],
    var datapath = uuid2str(ls._uuid),
    var port_id = FlatMap(ls.ports),
    nb.Logical_Switch_Port(._uuid = port_id, .enabled = enabled),
    is_enabled(enabled),
    var port_ids = Aggregate((datapath), group2set(port_id)).

/* Only create unknown group if the switch has ports with "unknown" address */
sb.Out_Multicast_Group (.datapath   = uuid2str(ls),
                        .name       = mC_UNKNOWN(),
                        .tunnel_key = 65534,
                        .ports      = set_map_uuid2str(port_ids)) :-
    LogicalSwitchUnknownPorts(ls, port_ids).

/*
 * MAC binding: records inserted by hypervisors; northd removes records for deleted logical ports
 */
sb.Out_MAC_Binding (.logical_port =   mb.logical_port,
                    .ip           =   mb.ip,
                    .mac          =   mb.mac,
                    .datapath     =   datapath_name) :-
    sb.MAC_Binding[mb],
    sb.UUIDMap_Datapath_Binding(datapath_name, Left{mb.datapath}).


/*
 * DHCP options: fixed table
 */
sb.Out_DHCP_Options (
    .name   = "offerip",
    .code   = 0,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "netmask",
    .code   = 1,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "router",
    .code   = 3,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "dns_server",
    .code   = 6,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "log_server",
    .code   = 7,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "lpr_server",
    .code   = 9,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "swap_server",
    .code   = 16,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "policy_filter",
    .code   = 21,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "router_solicitation",
    .code   = 32,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "nis_server",
    .code   = 41,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "ntp_server",
    .code   = 42,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "server_id",
    .code   = 54,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "tftp_server",
    .code   = 66,
    .__type = "ipv4"
).

sb.Out_DHCP_Options (
    .name   = "classless_static_route",
    .code   = 121,
    .__type = "static_routes"
).

sb.Out_DHCP_Options (
    .name   = "ms_classless_static_route",
    .code   = 249,
    .__type = "static_routes"
).

sb.Out_DHCP_Options (
    .name   = "ip_forward_enable",
    .code   = 19,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    .name   = "router_discovery",
    .code   = 31,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    .name   = "ethernet_encap",
    .code   = 36,
    .__type = "bool"
).

sb.Out_DHCP_Options (
    .name   = "default_ttl",
    .code   = 23,
    .__type = "uint8"
).

sb.Out_DHCP_Options (
    .name   = "tcp_ttl",
    .code   = 37,
    .__type = "uint8"
).

sb.Out_DHCP_Options (
    .name   = "mtu",
    .code   = 26,
    .__type = "uint16"
).

sb.Out_DHCP_Options (
    .name   = "lease_time",
    .code   = 51,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    .name   = "T1",
    .code   = 58,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    .name   = "T2",
    .code   = 59,
    .__type = "uint32"
).

sb.Out_DHCP_Options (
    .name   = "wpad",
    .code   = 252,
    .__type = "str"
).


/*
 * DHCPv6 options: fixed table
 */
sb.Out_DHCPv6_Options (
    .name   = "server_id",
    .code   = 2,
    .__type = "mac"
).

sb.Out_DHCPv6_Options (
    .name   = "ia_addr",
    .code   = 5,
    .__type = "ipv6"
).

sb.Out_DHCPv6_Options (
    .name   = "dns_server",
    .code   = 23,
    .__type = "ipv6"
).

sb.Out_DHCPv6_Options (
    .name   = "domain_search",
    .code   = 24,
    .__type = "str"
).


/*
 * DNS: copied from NB + datapaths column pointer to LS datapaths that use the record
 */

relation LogicalSwitchDNS(ls_uuid: uuid, dns_uuid: uuid)

/* Flatten the list of dns_records in Logical_Switch */
LogicalSwitchDNS(ls._uuid, dns_uuid) :-
    nb.Logical_Switch[ls],
    var dns_uuid = FlatMap(ls.dns_records).

sb.Out_DNS(.records      = nbdns.records,
           .datapaths    = datapaths,
           .external_ids = nbdns.external_ids) :-
    nb.DNS[nbdns],
    LogicalSwitchDNS(ls_uuid, nbdns._uuid),
    var datapaths = Aggregate((nbdns), group2set(uuid2str(ls_uuid))).

sb.Out_DNS(.records      = nbdns.records,
           .datapaths    = set_empty(),
           .external_ids = nbdns.external_ids) :-
    nb.DNS[nbdns],
    not LogicalSwitchDNS(_, nbdns._uuid).

/*
 * RBAC_Permission: fixed
 */

sb.Out_RBAC_Permission (
    .uuid_name      = "7df3749a-1754-4a78-afa4-3abf526fe510",
    .table          = "Chassis",
    .authorization  = set_singleton("name"),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "nb_cfg");
            set_insert(s, "external_ids");
            set_insert(s, "encaps");
            set_insert(s, "vtep_logical_switches");
            s
        }
).

sb.Out_RBAC_Permission (
    .uuid_name      = "94bec860-431e-4d95-82e7-3b75d8997241",
    .table          = "Encap",
    .authorization  = set_singleton("chassis_name"),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "type");
            set_insert(s, "options");
            set_insert(s, "ip");
            s
        }
).

sb.Out_RBAC_Permission (
    .uuid_name      = "d8ceff1a-2b11-48bd-802f-4a991aa4e908",
    .table          = "Port_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = false,
    .update         = set_singleton("chassis")
).

sb.Out_RBAC_Permission (
    .uuid_name      = "6ffdc696-8bfb-4d82-b620-a00d39270b2f",
    .table          = "MAC_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = {
            var s: Set<string> = set_empty();
            set_insert(s, "logical_port");
            set_insert(s, "ip");
            set_insert(s, "mac");
            set_insert(s, "datapath");
            s
        }
).

/*
 * RBAC_Role: fixed
 */
sb.Out_RBAC_Role (
    .name        = "ovn-controller",
    .permissions = {
            var m: Map<string, string> = map_empty();
            map_insert(m, "Chassis"     , "7df3749a-1754-4a78-afa4-3abf526fe510");
            map_insert(m, "Encap"       , "94bec860-431e-4d95-82e7-3b75d8997241");
            map_insert(m, "Port_Binding", "d8ceff1a-2b11-48bd-802f-4a991aa4e908");
            map_insert(m, "MAC_Binding" , "6ffdc696-8bfb-4d82-b620-a00d39270b2f");
            m
        }
).

typedef Direction = IN | OUT

typedef PipelineStage = PORT_SEC_L2
                      | PORT_SEC_IP
                      | PORT_SEC_ND
                      | PRE_ACL
                      | PRE_LB
                      | PRE_STATEFUL
                      | ACL
                      | QOS_MARK
                      | QOS_METER
                      | LB
                      | STATEFUL
                      | ARP_ND_RSP
                      | DHCP_OPTIONS
                      | DHCP_RESPONSE
                      | DNS_LOOKUP
                      | DNS_RESPONSE
                      | L2_LKUP
                      | ADMISSION
                      | IP_INPUT
                      | DEFRAG
                      | UNSNAT
                      | DNAT
                      | ND_RA_OPTIONS
                      | ND_RA_RESPONSE
                      | IP_ROUTING
                      | ARP_RESOLVE
                      | GW_REDIRECT
                      | ARP_REQUEST
                      | UNDNAT
                      | SNAT
                      | EGR_LOOP
                      | DELIVERY

function switch_stage(direction: Direction, stage: PipelineStage): integer =
{
    match ((direction, stage)) {
        (IN,  PORT_SEC_L2)   -> 0,
        (IN,  PORT_SEC_IP)   -> 1,
        (IN,  PORT_SEC_ND)   -> 2,
        (IN,  PRE_ACL)       -> 3,
        (IN,  PRE_LB)        -> 4,
        (IN,  PRE_STATEFUL)  -> 5,
        (IN,  ACL)           -> 6,
        (IN,  QOS_MARK)      -> 7,
        (IN,  QOS_METER)     -> 8,
        (IN,  LB)            -> 9,
        (IN,  STATEFUL)      -> 10,
        (IN,  ARP_ND_RSP)    -> 11,
        (IN,  DHCP_OPTIONS)  -> 12,
        (IN,  DHCP_RESPONSE) -> 13,
        (IN,  DNS_LOOKUP)    -> 14,
        (IN,  DNS_RESPONSE)  -> 15,
        (IN,  L2_LKUP)       -> 16,
        (OUT, PRE_LB)        -> 0,
        (OUT, PRE_ACL)       -> 1,
        (OUT, PRE_STATEFUL)  -> 2,
        (OUT, LB)            -> 3,
        (OUT, ACL)           -> 4,
        (OUT, QOS_MARK)      -> 5,
        (OUT, QOS_METER)     -> 6,
        (OUT, STATEFUL)      -> 7,
        (OUT, PORT_SEC_IP)   -> 8,
        (OUT, PORT_SEC_L2)   -> 9,
        _                    -> 64'hffffffffffffffff /* alternatively crash? */
    }
}

function router_stage(direction: Direction, stage: PipelineStage): integer =
{
    match ((direction, stage)) {
        (IN,  ADMISSION)     -> 0,
        (IN,  IP_INPUT)      -> 1,
        (IN,  DEFRAG)        -> 2,
        (IN,  UNSNAT)        -> 3,
        (IN,  DNAT)          -> 4,
        (IN,  ND_RA_OPTIONS) -> 5,
        (IN,  ND_RA_RESPONSE)-> 6,
        (IN,  IP_ROUTING)    -> 7,
        (IN,  ARP_RESOLVE)   -> 8,
        (IN,  GW_REDIRECT)   -> 9,
        (IN,  ARP_REQUEST)   -> 10,
        (OUT, UNDNAT)        -> 0,
        (OUT, SNAT)          -> 1,
        (OUT, EGR_LOOP)      -> 2,
        (OUT, DELIVERY)      -> 3,
        _                    -> 64'hffffffffffffffff /* alternatively crash? */
    }
}

/* Register definitions specific to switches. */
function rEGBIT_CONNTRACK_DEFRAG() : string = "reg0[0]"
function rEGBIT_CONNTRACK_COMMIT() : string = "reg0[1]"
function rEGBIT_CONNTRACK_NAT()    : string = "reg0[2]"
function rEGBIT_DHCP_OPTS_RESULT() : string = "reg0[3]"
function rEGBIT_DNS_LOOKUP_RESULT(): string = "reg0[4]"
function rEGBIT_ND_RA_OPTS_RESULT(): string = "reg0[5]"

/* Register definitions for switches and routers. */
function rEGBIT_NAT_REDIRECT()     : string = "reg9[0]"
/* Indicate that this packet has been recirculated using egress
 * loopback.  This allows certain checks to be bypassed, such as a
 * logical router dropping packets with source IP address equals
 * one of the logical router's own IP addresses. */
function rEGBIT_EGRESS_LOOPBACK()  : string = "reg9[1]"

/*
 * Logical_Flow
   relation Out_Logical_Flow (
        logical_datapath: string,
        pipeline: string,
        table_id: integer,
        priority: integer,
        __match: string,
        actions: string,
        external_ids: Map<string,string>)
 */



/* Logical switch ingress table 0: admission control framework (priority 100) */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Logical VLANs not supported */
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_L2),
                            .priority         = 100,
                            .__match          = "vlan.present",
                            .actions          = "drop;",
                            .external_ids     = map_empty() /*TODO: check*/);

        /* Broadcast/multicast source address is invalid */
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_L2),
                            .priority         = 100,
                            .__match          = "eth.src[40]",
                            .actions          = "drop;",
                            .external_ids     = map_empty() /*TODO: check*/)
    }
    /* Port security flows have priority 50 (see below) and will continue to the next table
       if packet source is acceptable. */
}

/* Logical port is enabled if it does not have an enabled flag or the flag is true */
function is_enabled(s: Set<bool>): bool = {
    set_nth(s, 0) != Some{false}
}

// space-separated vector of strings
function vec_space_sep(items: Vec<string>): string = {
    string_join(items, " ")
}

// space-separated set of strings
function set_space_sep(items: Set<string>): string = {
    vec_space_sep(set2vec(items))
}

relation LSPortPSAddresses(lsport:   uuid,
                           ps_addrs: lport_addresses)

LSPortPSAddresses(lsport, ps_addrs) :-
    nb.Logical_Switch_Port(._uuid = lsport, .port_security = port_security),
    var port_sec = FlatMap(port_security),
    Some{var ps_addrs} = extract_lsp_addresses(port_sec).

relation LSPortPSEthAddresses(lsport: uuid,
                              addrs:  Set<string>)

LSPortPSEthAddresses(lsport, addrs) :-
    LSPortPSAddresses(lsport, ps_addrs),
    var addrs = Aggregate((lsport), group2set(ps_addrs.ea_s)).

LSPortPSEthAddresses(lsport, set_empty()) :-
    nb.Logical_Switch_Port(._uuid = lsport),
    not LSPortPSAddresses(lsport,_).

relation LSPortAddresses(lsport: uuid,
                         addrs:  lport_addresses)

LSPortAddresses(lsport, addrs) :-
    nb.Logical_Switch_Port(._uuid = lsport, .addresses = addresses),
    var address = FlatMap(addresses),
    Some{var addrs} = extract_lsp_addresses(address).

LSPortAddresses(lsport, addrs) :-
    nb.Logical_Switch_Port(._uuid = lsport, .dynamic_addresses = addresses),
    var address = FlatMap(addresses),
    Some{var addrs} = extract_lsp_addresses(address).

relation LSPortIPv4Address(lsport: uuid,
                           ea_s:   string,
                           addr:   ipv4_netaddr)

LSPortIPv4Address(lsport, ea_s, addr) :-
    LSPortAddresses(lsport, LPortAddress{.ea_s = ea_s, .ipv4_addrs = addrs}),
    var addr = FlatMap(addrs).

relation LSPortIPv6Address(lsport: uuid,
                           ea_s:   string,
                           addr:   ipv6_netaddr)

LSPortIPv6Address(lsport, ea_s, addr) :-
    LSPortAddresses(lsport, LPortAddress{.ea_s = ea_s, .ipv6_addrs = addrs}),
    var addr = FlatMap(addrs).


/* FIXME: what happens when extract_lrp_networks fails. We currently add the port anyway,
 * but do not create an LRPortNetworks entry for it. */

/* Precompute frequently used router port attributes.
 */
relation LogicalRouterPortAttrs(
    lrp: nb.Logical_Router_Port,
    json_key: string,
    networks: lport_addresses,
    lr_uuid: uuid,
    lr_name: string,
    is_redirect: bool
)

LogicalRouterPortAttrs(.lrp         = lrp,
                       .json_key    = json_string_escape(lrp.name),
                       .networks    = networks,
                       .lr_uuid     = lr_uuid,
                       .lr_name     = uuid2str(lr_uuid),
                       .is_redirect = is_redirect) :-
    nb.Logical_Router_Port[lrp],
    Some{var networks} = extract_lrp_networks(lrp.mac, lrp.networks),
    LogicalPortRouter(lrp._uuid, lr_uuid),
    RouterPortIsRedirect(lrp._uuid, is_redirect).

relation LRPortNetworksIPv4Addr(lrport: uuid, addr: ipv4_netaddr)

LRPortNetworksIPv4Addr(lrport, addr) :-
    LogicalRouterPortAttrs(.lrp = nb.Logical_Router_Port{._uuid = lrport}, .networks = networks),
    var addr = FlatMap(networks.ipv4_addrs).

function build_port_security_ipv6_flow(
    pipeline: Direction,
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var ip6_addrs: Vec<string> = vec_empty();

    /* Allow link-local address. */
    vec_push(ip6_addrs, ipv6_string_mapped(in6_generate_lla(ea)));

    /* Allow ip6.dst=ff00::/8 for multicast packets */
    if (pipeline == OUT) {
        vec_push(ip6_addrs, "ff00::/8")
    } else ();
    for (addr in ipv6_addrs) {
        vec_push(ip6_addrs, ipv6_string_mapped(addr.addr))
    };

    $" && ${if (pipeline == IN) \"ip6.src\" else \"ip6.dst\"} == {${string_join(ip6_addrs, \", \")}}"
}

function build_port_security_ipv6_nd_flow(
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var __match = $" && ip6 && nd && ((nd.sll == ${eth_addr_zero()} || " ++
                  $"nd.sll == ${ea}) || ((nd.tll == ${eth_addr_zero()} || " ++
                  $"nd.tll == ${ea})";
    if (vec_is_empty(ipv6_addrs)) {
        __match ++ "))"
    } else {
        var ip6_str = ipv6_string_mapped(in6_generate_lla(ea));
        __match = __match ++ $" && (nd.target == ${ip6_str}";

        for(addr in ipv6_addrs) {
            ip6_str = ipv6_string_mapped(addr.addr);
            __match = __match ++ $" || nd.target == ${ip6_str}"
        };
        __match ++ ")))"
    }
}

relation PortInGroup(port: uuid, group: uuid)

PortInGroup(port, group) :-
    nb.Port_Group(._uuid = group, .ports = ports),
    var port = FlatMap(ports).

/* All ACLs associated with logical switch */
relation LogicalSwitchACL(ls: uuid, acl: uuid)

LogicalSwitchACL(ls, acl) :-
    nb.Logical_Switch(._uuid = ls, .acls = acls),
    var acl = FlatMap(acls).

LogicalSwitchACL(ls, acl) :-
    nb.Logical_Switch(._uuid = ls, .ports = ports),
    var port_id = FlatMap(ports),
    PortInGroup(port_id, group_id),
    nb.Port_Group(._uuid = group_id, .acls = acls),
    var acl = FlatMap(acls).

relation LogicalSwitchStatefulACL(ls: uuid, acl: uuid)

LogicalSwitchStatefulACL(ls, acl) :-
    LogicalSwitchACL(ls, acl),
    nb.ACL(._uuid = acl, .action = "allow-related").

relation LogicalSwitchHasStatefulACL(ls: uuid, has_stateful_acl: bool)

LogicalSwitchHasStatefulACL(ls, true) :-
    LogicalSwitchStatefulACL(ls, _).

LogicalSwitchHasStatefulACL(ls, false) :-
    nb.Logical_Switch(._uuid = ls),
    not LogicalSwitchStatefulACL(ls, _).

/* Logical switch ports of type router */
relation LogicalSwitchRouterPort(ls: uuid, lrp: uuid)

LogicalSwitchRouterPort(ls, port) :-
    nb.Logical_Switch(._uuid = ls, .ports = ports),
    var port = FlatMap(ports),
    nb.Logical_Switch_Port(._uuid = port, .__type = "router", .options = options),
    Some{var router_port} = map_get(options, "router-port").


relation LogicalSwitchLocalnetPort(ls: uuid, lsp: uuid)

LogicalSwitchLocalnetPort(ls, port) :-
    nb.Logical_Switch(._uuid = ls, .ports = ports),
    var port = FlatMap(ports),
    nb.Logical_Switch_Port(._uuid = port, .__type = "localnet").

relation LSPSwitchLocalnetPort(lsp: uuid, localnet_port: uuid)

LSPSwitchLocalnetPort(lsp, localnet_port) :-
    LogicalPortSwitch(lsp, ls),
    LogicalSwitchLocalnetPort(ls, localnet_port).

relation LSPSwitchHasLocalnetPort(lsp: uuid, has_localnet_port: bool)

LSPSwitchHasLocalnetPort(lsp, true) :-
    LSPSwitchLocalnetPort(lsp, _).

LSPSwitchHasLocalnetPort(lsp, false) :-
    nb.Logical_Switch_Port(._uuid = lsp),
    not LSPSwitchLocalnetPort(lsp, _).

/* Pre-ACL */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Ingress and Egress Pre-ACL Table (Priority 0): Packets are
         * allowed by default. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, PRE_ACL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, PRE_ACL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        /* If there are any stateful ACL rules in this datapath, we must
         * send all IP packets through the conntrack action, which handles
         * defragmentation, in order to match L4 headers. */
        for (LogicalSwitchHasStatefulACL(ls._uuid, true)) {
            for (LogicalSwitchRouterPort(ls._uuid, lsp_uuid)) {
                for (nb.Logical_Switch_Port(._uuid = lsp_uuid, .name = lsp_name)) {
                    /* Can't use ct() for router ports. Consider the
                     * following configuration: lp1(10.0.0.2) on
                     * hostA--ls1--lr0--ls2--lp2(10.0.1.2) on hostB, For a
                     * ping from lp1 to lp2, First, the response will go
                     * through ct() with a zone for lp2 in the ls2 ingress
                     * pipeline on hostB.  That ct zone knows about this
                     * connection. Next, it goes through ct() with the zone
                     * for the router port in the egress pipeline of ls2 on
                     * hostB.  This zone does not know about the connection,
                     * as the icmp request went through the logical router
                     * on hostA, not hostB. This would only work with
                     * distributed conntrack state across all chassis. */
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, PRE_ACL),
                        .priority         = 110,
                        .__match          = $"ip && inport == ${json_string_escape(lsp_name)}",
                        .actions          = "next;",
                        .external_ids     = map_empty());
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, PRE_ACL),
                        .priority         = 110,
                        .__match          = $"ip && outport == ${json_string_escape(lsp_name)}",
                        .actions          = "next;",
                        .external_ids     = map_empty())
                }
            };
            for (LogicalSwitchLocalnetPort(.ls = ls._uuid, .lsp = lsp_uuid)) {
                for (nb.Logical_Switch_Port(._uuid = lsp_uuid, .name = lsp_name)) {
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, PRE_ACL),
                        .priority         = 110,
                        .__match          = $"ip && inport == ${json_string_escape(lsp_name)}",
                        .actions          = "next;",
                        .external_ids     = map_empty());
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, PRE_ACL),
                        .priority         = 110,
                        .__match          = $"ip && outport == ${json_string_escape(lsp_name)}",
                        .actions          = "next;",
                        .external_ids     = map_empty())
                }
            };

            /* Ingress and Egress Pre-ACL Table (Priority 110).
             *
             * Not to do conntrack on ND and ICMP destination
             * unreachable packets. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, PRE_ACL),
                .priority         = 110,
                .__match          = "nd || nd_rs || nd_ra || icmp4.type == 3 || " ++
                                    "icmp6.type == 1 || (tcp && tcp.flags == 4)",
                .actions          = "next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, PRE_ACL),
                .priority         = 110,
                .__match          = "nd || nd_rs || nd_ra || icmp4.type == 3 || " ++
                                    "icmp6.type == 1 || (tcp && tcp.flags == 4)",
                .actions          = "next;",
                .external_ids     = map_empty());

            /* Ingress and Egress Pre-ACL Table (Priority 100).
             *
             * Regardless of whether the ACL is "from-lport" or "to-lport",
             * we need rules in both the ingress and egress table, because
             * the return traffic needs to be followed.
             *
             * 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
             * it to conntrack for tracking and defragmentation. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, PRE_ACL),
                .priority         = 100,
                .__match          = "ip",
                .actions          = $"${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, PRE_ACL),
                .priority         = 100,
                .__match          = "ip",
                .actions          = $"${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
                .external_ids     = map_empty())
        }
    }
}



relation LogicalSwitchLB(ls: uuid, lb: uuid)

LogicalSwitchLB(ls, lb) :-
    nb.Logical_Switch(._uuid = ls, .load_balancer = lb_ids),
    var lb = FlatMap(lb_ids).

relation LogicalRouterLB(lr: uuid, lb: uuid)

LogicalRouterLB(lr, lb) :-
    nb.Logical_Router(._uuid = lr, .load_balancer = lb_ids),
    var lb = FlatMap(lb_ids).

relation LBVIP(lb: uuid, vip: (string, string))

LBVIP(lb, vip) :-
    nb.Load_Balancer(._uuid = lb, .vips = vips),
    var vip = FlatMap(vips).

/* Load balancer VIPs associated with Logical_Switch */
relation LogicalSwitchLBVIP(ls: uuid, vip: (string, string))

LogicalSwitchLBVIP(ls, vip) :-
    LogicalSwitchLB(ls, lb_id),
    LBVIP(lb_id, vip).

relation LogicalSwitchHasLBVIP(ls: uuid)

LogicalSwitchHasLBVIP(ls) :-
    LogicalSwitchLBVIP(ls, _).

relation LogicalRouterLBVIP(lr: uuid, vip: (string, string))

LogicalRouterLBVIP(lr, vip) :-
    LogicalRouterLB(lr, lb_id),
    LBVIP(lb_id, vip).

/* Pre-LB */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Do not send ND packets to conntrack */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, PRE_LB),
            .priority         = 110,
            .__match          = "nd || nd_rs || nd_ra",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, PRE_LB),
            .priority         = 110,
            .__match          = "nd || nd_rs || nd_ra",
            .actions          = "next;",
            .external_ids     = map_empty());

        /* Allow all packets to go to next tables by default. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, PRE_LB),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, PRE_LB),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        /* 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
         * packet to conntrack for defragmentation. */
        for (LogicalSwitchLBVIP(ls._uuid, vip)) {
            (var k, _) = vip in
            /* Ignore L4 port information in the key because fragmented packets
             * may not have L4 information.  The pre-stateful table will send
             * the packet through ct() action to de-fragment. In stateful
             * table, we will eventually look at L4 information. */
            Some{(var ip_address, _, var addr_family)} = ip_address_and_port_from_lb_key(k) in
            var __match = if (addr_family == aF_INET()) {
                   $"ip && ip4.dst == ${ip_address}"
                } else {
                   $"ip && ip6.dst == ${ip_address}"
                } in
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, PRE_LB),
                .priority         = 100,
                .__match          = __match,
                .actions          = $"${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
                .external_ids     = map_empty())
        };
        for (LogicalSwitchHasLBVIP(ls._uuid)) {
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, PRE_LB),
                .priority         = 100,
                .__match          = "ip",
                .actions          = $"${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
                .external_ids     = map_empty())
        }
    }
}

/* Pre-stateful */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Ingress and Egress pre-stateful Table (Priority 0): Packets are
         * allowed by default. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, PRE_STATEFUL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, PRE_STATEFUL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        /* If REGBIT_CONNTRACK_DEFRAG is set as 1, then the packets should be
         * sent to conntrack for tracking and defragmentation. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, PRE_STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_DEFRAG()} == 1",
            .actions          = "ct_next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, PRE_STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_DEFRAG()} == 1",
            .actions          = "ct_next;",
            .external_ids     = map_empty())
    }
}

function build_acl_log(acl: nb.ACL): string =
{
    if (not acl.log) {
        ""
    } else {
        var strs: Vec<string> = vec_empty();
        match (set_nth(acl.name, 0)) {
            None -> (),
            Some{name} -> vec_push(strs, $"name=\"${name}\"")
        };
        /* If a severity level isn't specified, default to "info". */
        match (set_nth(acl.severity, 0)) {
            None -> vec_push(strs, "severity=info"),
            Some{severity} -> vec_push(strs, $"severity=${severity}")
        };
        match (acl.action) {
            "drop" -> {
                vec_push(strs, "verdict=drop")
            },
            "reject" -> {
                vec_push(strs, "verdict=reject")
            },
            "allow" -> {
                vec_push(strs, "verdict=allow")
            },
            "allow-related" -> {
                vec_push(strs, "verdict=allow")
            },
            _ -> ()
        };
        match (set_nth(acl.meter, 0)) {
            None -> (),
            Some{meter} -> vec_push(strs, $"meter=${meter}")
        };
        $"log(${string_join(strs, \", \")}); "
    }
}

/* Due to various hard-coded priorities need to implement ACLs, the
 * northbound database supports a smaller range of ACL priorities than
 * are available to logical flows.  This value is added to an ACL
 * priority to determine the ACL's logical flow priority. */
function oVN_ACL_PRI_OFFSET(): integer = 1000

/* Intermediate relation that stores reject ACLs.
 * The following rules generate logical flows for these ACLs.
 */
relation Reject(lsname: string, pipeline: string, stage: integer, acl: nb.ACL, extra_match: string, extra_actions: string)

/* build_reject_acl_rules() */
for (Reject(lsname, pipeline, stage, acl, extra_match, extra_actions)) {
    var ingress = (pipeline == "ingress") in {
        /* TCP */
        var __match = if (extra_match != "") {
                $"(${extra_match}) && "
            } else {
                ""
            } ++ $"ip4 && tcp && (${acl.__match})" in
        var actions = $"${build_acl_log(acl)}reg0 = 0; " ++
                      "eth.dst <-> eth.src; ip4.dst <-> ip4.src; " ++
                      $"tcp_reset { outport <-> inport; ${if ingress \"output;\" else \"next(pipeline=ingress,table=0);\"} };" in
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = pipeline,
            .table_id         = stage,
            .priority         = acl.priority + oVN_ACL_PRI_OFFSET() + 10,
            .__match          = __match,
            .actions          = actions,
            .external_ids     = map_empty());

        var __match = if (extra_match != "") {
                $"(${extra_match}) && "
            } else { "" } ++
            $"ip6 && tcp && (${acl.__match})" in
        var actions = $"${build_acl_log(acl)}reg0 = 0; "            ++
                      "eth.dst <-> eth.src; ip6.dst <-> ip6.src; "  ++
                      $"tcp_reset { outport <-> inport; ${if ingress \"output;\" else \"next(pipeline=ingress,table=0);\"} };" in
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = pipeline,
            .table_id         = stage,
            .priority         = acl.priority + oVN_ACL_PRI_OFFSET() + 10,
            .__match          = __match,
            .actions          = actions,
            .external_ids     = map_empty());

        /* IP traffic */
        var __match = if (extra_match != "") {
                $"(${extra_match}) && "
            } else { "" } ++
            $"ip4 && (${acl.__match})" in
        var actions = build_acl_log(acl) ++
                      if (extra_actions != "") {
                          $"${extra_actions} "
                      } else { "" } ++
                      "reg0 = 0; eth.dst <-> eth.src; ip4.dst <-> ip4.src; " ++
                      $"icmp4 { outport <-> inport; ${if ingress \"output;\" else \"next(pipeline=ingress,table=0);\"} };" in
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = pipeline,
            .table_id         = stage,
            .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
            .__match          = __match,
            .actions          = actions,
            .external_ids     = map_empty());


        var __match = if (extra_match != "") {
                $"(${extra_match}) && "
            } else { "" } ++
            $"ip6 && (${acl.__match})" in
        var actions = build_acl_log(acl) ++
                      if (extra_actions != "") {
                          $"${extra_actions} "
                      } else { "" } ++
                      "reg0 = 0; icmp6 { "  ++
                      "eth.dst <-> eth.src; ip6.dst <-> ip6.src; " ++
                      $"outport <-> inport; ${if ingress \"output;\" else \"next(pipeline=ingress,table=0);\"} };" in
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = pipeline,
            .table_id         = stage,
            .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
            .__match          = __match,
            .actions          = actions,
            .external_ids     = map_empty())
    }
}

/* build_acls */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in
    for (LogicalSwitchHasStatefulACL(ls._uuid, has_stateful)) {
        /* Ingress and Egress ACL Table (Priority 0): Packets are allowed by
         * default.  A related rule at priority 1 is added below if there
         * are any stateful ACLs in this datapath. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, ACL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, ACL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        if (has_stateful) {
            /* Ingress and Egress ACL Table (Priority 1).
             *
             * By default, traffic is allowed.  This is partially handled by
             * the Priority 0 ACL flows added earlier, but we also need to
             * commit IP flows.  This is because, while the initiater's
             * direction may not have any stateful rules, the server's may
             * and then its return traffic would not have an associated
             * conntrack entry and would return "+invalid".
             *
             * We use "ct_commit" for a connection that is not already known
             * by the connection tracker.  Once a connection is committed,
             * subsequent packets will hit the flow at priority 0 that just
             * uses "next;"
             *
             * We also check for established connections that have ct_label.blocked
             * set on them.  That's a connection that was disallowed, but is
             * now allowed by policy again since it hit this default-allow flow.
             * We need to set ct_label.blocked=0 to let the connection continue,
             * which will be done by ct_commit() in the "stateful" stage.
             * Subsequent packets will hit the flow at priority 0 that just
             * uses "next;". */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, ACL),
                .priority         = 1,
                .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
                .actions          = $"${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 1,
                .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
                .actions          = $"${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
                .external_ids     = map_empty());

            /* Ingress and Egress ACL Table (Priority 65535).
             *
             * Always drop traffic that's in an invalid state.  Also drop
             * reply direction packets for connections that have been marked
             * for deletion (bit 0 of ct_label is set).
             *
             * This is enforced at a higher priority than ACLs can be defined. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, ACL),
                .priority         = 65535,
                .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
                .actions          = "drop;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 65535,
                .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
                .actions          = "drop;",
                .external_ids     = map_empty());

            /* Ingress and Egress ACL Table (Priority 65535).
             *
             * Allow reply traffic that is part of an established
             * conntrack entry that has not been marked for deletion
             * (bit 0 of ct_label).  We only match traffic in the
             * reply direction because we want traffic in the request
             * direction to hit the currently defined policy from ACLs.
             *
             * This is enforced at a higher priority than ACLs can be defined. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, ACL),
                .priority         = 65535,
                .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv " ++
                                    "&& ct.rpl && ct_label.blocked == 0",
                .actions          = "next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 65535,
                .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv " ++
                                    "&& ct.rpl && ct_label.blocked == 0",
                .actions          = "next;",
                .external_ids     = map_empty());

            /* Ingress and Egress ACL Table (Priority 65535).
             *
             * Allow traffic that is related to an existing conntrack entry that
             * has not been marked for deletion (bit 0 of ct_label).
             *
             * This is enforced at a higher priority than ACLs can be defined.
             *
             * NOTE: This does not support related data sessions (eg,
             * a dynamically negotiated FTP data channel), but will allow
             * related traffic such as an ICMP Port Unreachable through
             * that's generated from a non-listening UDP port.  */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, ACL),
                .priority         = 65535,
                .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv " ++
                                    "&& ct_label.blocked == 0",
                .actions          = "next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 65535,
                .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv " ++
                                    "&& ct_label.blocked == 0",
                .actions          = "next;",
                .external_ids     = map_empty());

            /* Ingress and Egress ACL Table (Priority 65535).
             *
             * Not to do conntrack on ND packets. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, ACL),
                .priority         = 65535,
                .__match          = "nd",
                .actions          = "next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 65535,
                .__match          = "nd",
                .actions          = "next;",
                .external_ids     = map_empty())
        };

        /* Ingress or Egress ACL Table (Various priorities). */
        for (LogicalSwitchACL(.ls = ls._uuid, .acl = acl_uuid)) {
            /* consider_acl */
            for (acl in nb.ACL(._uuid = acl_uuid)) {
                var ingress = acl.direction == "from-lport" in
                var stage = if ingress switch_stage(IN, ACL) else switch_stage(OUT, ACL) in
                var pipeline = if ingress "ingress" else "egress" in
                var stage_hint = map_singleton("stage-hint", $"${hex(acl_uuid[127:96])}") in
                if (acl.action == "allow" or acl.action == "allow-related") {
                    /* If there are any stateful flows, we must even commit "allow"
                     * actions.  This is because, while the initiater's
                     * direction may not have any stateful rules, the server's
                     * may and then its return traffic would not have an
                     * associated conntrack entry and would return "+invalid". */
                    if (not has_stateful) {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = pipeline,
                            .table_id         = stage,
                            .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                            .__match          = acl.__match,
                            .actions          = $"${build_acl_log(acl)}next;",
                            .external_ids     = stage_hint)
                    } else {
                        /* Commit the connection tracking entry if it's a new
                         * connection that matches this ACL.  After this commit,
                         * the reply traffic is allowed by a flow we create at
                         * priority 65535, defined earlier.
                         *
                         * It's also possible that a known connection was marked for
                         * deletion after a policy was deleted, but the policy was
                         * re-added while that connection is still known.  We catch
                         * that case here and un-set ct_label.blocked (which will be done
                         * by ct_commit in the "stateful" stage) to indicate that the
                         * connection should be allowed to resume.
                         */
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = pipeline,
                            .table_id         = stage,
                            .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                            .__match          = $"((ct.new && !ct.est) || (!ct.new && ct.est && !ct.rpl " ++
                                                $"&& ct_label.blocked == 1)) && (${acl.__match})",
                            .actions          = $"${rEGBIT_CONNTRACK_COMMIT()} = 1; ${build_acl_log(acl)}next;",
                            .external_ids     = stage_hint);

                        /* Match on traffic in the request direction for an established
                         * connection tracking entry that has not been marked for
                         * deletion.  There is no need to commit here, so we can just
                         * proceed to the next table. We use this to ensure that this
                         * connection is still allowed by the currently defined
                         * policy. */
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = pipeline,
                            .table_id         = stage,
                            .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                            .__match          = $"!ct.new && ct.est && !ct.rpl" ++
                                                $" && ct_label.blocked == 0 && (${acl.__match})",
                            .actions          = $"${build_acl_log(acl)}next;",
                            .external_ids     = stage_hint)
                    }
                } else if (acl.action == "drop" or acl.action == "reject") {
                    /* The implementation of "drop" differs if stateful ACLs are in
                     * use for this datapath.  In that case, the actions differ
                     * depending on whether the connection was previously committed
                     * to the connection tracker with ct_commit. */
                    if (has_stateful) {
                        /* If the packet is not part of an established connection, then
                         * we can simply reject/drop it. */
                        var __match = "(!ct.est || (ct.est && ct_label.blocked == 1))" in
                        if (acl.action == "reject") {
                            Reject(lsname, pipeline, stage, acl, __match, "")
                        } else {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = pipeline,
                                .table_id         = stage,
                                .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                                .__match          = __match ++ $" && (${acl.__match})",
                                .actions          = $"${build_acl_log(acl)}/* drop */",
                                .external_ids     = stage_hint)
                        };
                        /* For an existing connection without ct_label set, we've
                         * encountered a policy change. ACLs previously allowed
                         * this connection and we committed the connection tracking
                         * entry.  Current policy says that we should drop this
                         * connection.  First, we set bit 0 of ct_label to indicate
                         * that this connection is set for deletion.  By not
                         * specifying "next;", we implicitly drop the packet after
                         * updating conntrack state.  We would normally defer
                         * ct_commit() to the "stateful" stage, but since we're
                         * rejecting/dropping the packet, we go ahead and do it here.
                         */
                        var __match = "ct.est && ct_label.blocked == 0" in
                        var actions = "ct_commit(ct_label=1/1); " in
                        if (acl.action == "reject") {
                            Reject(lsname, pipeline, stage, acl, __match, actions)
                        } else {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = pipeline,
                                .table_id         = stage,
                                .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                                .__match          = __match ++ $" && (${acl.__match})",
                                .actions          = $"${build_acl_log(acl)}/* drop */",
                                .external_ids     = stage_hint)
                        }
                    } else {
                        /* There are no stateful ACLs in use on this datapath,
                         * so a "reject/drop" ACL is simply the "reject/drop"
                         * logical flow action in all cases. */
                        if (acl.action == "reject") {
                            Reject(lsname, pipeline, stage, acl, "", "")
                        } else {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = pipeline,
                                .table_id         = stage,
                                .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                                .__match          = acl.__match,
                                .actions          = $"${build_acl_log(acl)}/* drop */",
                                .external_ids     = stage_hint)
                        }
                    }
                }
            }
        };

        /* Add 34000 priority flow to allow DHCP reply from ovn-controller to all
         * logical ports of the datapath if the CMS has configured DHCPv4 options.
         * */
        for (LogicalPortSwitch(.lport = port_id, .lswitch = ls._uuid)) {
            for (nb.Logical_Switch_Port(._uuid = port_id, .name = port_name,
                                        .dhcpv4_options = dhcpv4_options, .dhcpv6_options = dhcpv6_options))
            {
                Some{var dhcpv4_options_uuid} = set_nth(dhcpv4_options, 0) in
                for (nb.DHCP_Options(._uuid = dhcpv4_options_uuid, .options = options)) {
                    (Some{var server_id}, Some{var server_mac}, Some{var lease_time}) =
                        (map_get(options, "server_id"), map_get(options, "server_mac"), map_get(options, "lease_time")) in
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, ACL),
                        .priority         = 34000,
                        .__match          = $"outport == \"${port_name}\" && eth.src == ${server_mac} " ++
                                            "&& ip4.src == ${server_id} && udp && udp.src == 67 "       ++
                                            "&& udp.dst == 68",
                        .actions          = if (has_stateful) "ct_commit; next;" else "next;",
                        .external_ids     = map_empty())
                };
                Some{var dhcpv6_options_uuid} = set_nth(dhcpv6_options, 0) in
                for (nb.DHCP_Options(._uuid = dhcpv6_options_uuid, .options = options)) {
                    Some{var server_mac} = map_get(options, "server_id") in
                    Some{var ea} = eth_addr_from_string(server_mac) in
                    var server_ip = ipv6_string_mapped(in6_generate_lla(ea)) in
                    /* Get the link local IP of the DHCPv6 server from the
                     * server MAC. */
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, ACL),
                        .priority         = 34000,
                        .__match          = $"outport == \"${port_name}\" && eth.src == ${server_mac} " ++
                                            $"&& ip6.src == ${server_ip} && udp && udp.src == 547 "     ++
                                            "&& udp.dst == 546",
                        .actions          = if has_stateful "ct_commit; next;" else "next;",
                        .external_ids     = map_empty())
                }
            }
        };

        /* Add a 34000 priority flow to advance the DNS reply from ovn-controller,
         * if the CMS has configured DNS records for the datapath.
         */
        for (LSHasDNSRecords(ls._uuid)) {
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, ACL),
                .priority         = 34000,
                .__match          = "udp.src == 53",
                .actions          = if has_stateful "ct_commit; next;" else "next;",
                .external_ids     = map_empty())
        }
    }
}

relation LogicalSwitchQoS(ls: uuid, qos_rule: uuid)

LogicalSwitchQoS(ls, qos_rule) :-
    nb.Logical_Switch(._uuid = ls, .qos_rules = qos_rules),
    var qos_rule = FlatMap(qos_rules).

relation QoSAction(qos: uuid, key_action: string, value_action: integer)

QoSAction(qos, k, v) :-
    nb.QoS(._uuid = qos, .action = actions),
    var action = FlatMap(actions),
    (var k, var v) = action.

/* QoS rules */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, QOS_MARK),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, QOS_MARK),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, QOS_METER),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, QOS_METER),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        for (LogicalSwitchQoS(ls._uuid, qos_rule_id)) {
            for(qos in nb.QoS(._uuid = qos_rule_id)) {
                var ingress = if (qos.direction == "from-lport") true else false in
                var pipeline = if ingress "ingress" else "egress" in {
                    var stage = if ingress switch_stage(IN, QOS_MARK) else switch_stage(OUT, QOS_MARK) in
                    /* FIXME: Can value_action be negative */
                    for (QoSAction(qos_rule_id, key_action, value_action)) {
                        if (key_action == "dscp") {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = pipeline,
                                .table_id         = stage,
                                .priority         = qos.priority,
                                .__match          = qos.__match,
                                .actions          = $"ip.dscp = ${value_action}; next;",
                                .external_ids     = map_empty())
                        }
                    };

                    (var burst: bit<64>, var rate: bit<64>) = {
                        var rate: bit<64> = 0;
                        var burst: bit<64> = 0;
                        for (bw in qos.bandwidth) {
                            /* FIXME: Can value_bandwidth be negative? */
                            (var key_bandwidth, var value_bandwidth) = bw;
                            if (key_bandwidth == "rate") {
                                rate = value_bandwidth
                            } else if (key_bandwidth == "burst") {
                                burst = value_bandwidth
                            } else ()
                        };
                        (burst, rate)
                    } in
                    if (rate != 0) {
                        var stage = if (ingress) switch_stage(IN, QOS_METER) else switch_stage(OUT, QOS_METER) in
                        var meter_action = if (burst != 0) {
                                $"set_meter(${rate}, ${burst}); next;"
                            } else {
                                $"set_meter(${rate}); next;"
                            } in
                        /* Ingress and Egress QoS Meter Table.
                         *
                         * We limit the bandwidth of this flow by adding a meter table.
                         */
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = pipeline,
                            .table_id         = stage,
                            .priority         = qos.priority,
                            .__match          = qos.__match,
                            .actions          = meter_action,
                            .external_ids     = map_empty())
                    }
                }
            }
        }
    }
}

/* LB rules */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Ingress and Egress LB Table (Priority 0): Packets are allowed by
         * default.  */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, LB),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, LB),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        if (not set_is_empty(ls.load_balancer)) {
            /* Ingress and Egress LB Table (Priority 65535).
             *
             * Send established traffic through conntrack for just NAT. */
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "ingress",
                .table_id         = switch_stage(IN, LB),
                .priority         = 65535,
                .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv",
                .actions          = $"${rEGBIT_CONNTRACK_NAT()} = 1; next;",
                .external_ids     = map_empty());
            sb.Out_Logical_Flow(
                .logical_datapath = lsname,
                .pipeline         = "egress",
                .table_id         = switch_stage(OUT, LB),
                .priority         = 65535,
                .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv",
                .actions          = $"${rEGBIT_CONNTRACK_NAT()} = 1; next;",
                .external_ids     = map_empty())
        }
    }
}

/* stateful rules */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        /* Ingress and Egress stateful Table (Priority 0): Packets are
         * allowed by default. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, STATEFUL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, STATEFUL),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty());

        /* If REGBIT_CONNTRACK_COMMIT is set as 1, then the packets should be
         * committed to conntrack. We always set ct_label.blocked to 0 here as
         * any packet that makes it this far is part of a connection we
         * want to allow to continue. */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_COMMIT()} == 1",
            .actions          = "ct_commit(ct_label=0/1); next;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_COMMIT()} == 1",
            .actions          = "ct_commit(ct_label=0/1); next;",
            .external_ids     = map_empty());

        /* If REGBIT_CONNTRACK_NAT is set as 1, then packets should just be sent
         * through nat (without committing).
         *
         * REGBIT_CONNTRACK_COMMIT is set for new connections and
         * REGBIT_CONNTRACK_NAT is set for established connections. So they
         * don't overlap.
         */
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "ingress",
            .table_id         = switch_stage(IN, STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_NAT()} == 1",
            .actions          = "ct_lb;",
            .external_ids     = map_empty());
        sb.Out_Logical_Flow(
            .logical_datapath = lsname,
            .pipeline         = "egress",
            .table_id         = switch_stage(OUT, STATEFUL),
            .priority         = 100,
            .__match          = $"${rEGBIT_CONNTRACK_NAT()} == 1",
            .actions          = "ct_lb;",
            .external_ids     = map_empty());

        /* Load balancing rules for new connections get committed to conntrack
         * table.  So even if REGBIT_CONNTRACK_COMMIT is set in a previous table
         * a higher priority rule for load balancing below also commits the
         * connection, so it is okay if we do not hit the above match on
         * REGBIT_CONNTRACK_COMMIT. */
        for (LogicalSwitchLB(ls._uuid, lb_id)) {
            for (lb in nb.Load_Balancer(._uuid = lb_id)) {
                for (LBVIP(lb_id, (vip_key, vip_val))) {
                    Some{(var ip_address, var port, var addr_family)} = ip_address_and_port_from_lb_key(vip_key) in

                    /* New connections in Ingress table. */
                    var __match = if (addr_family == aF_INET()) {
                            $"ct.new && ip4.dst == ${ip_address}"
                        } else {
                            $"ct.new && ip6.dst == ${ip_address}"
                        } in
                    if (port != 0) {
                        var __match2 = __match ++
                            if (set_nth(lb.protocol, 0) == Some{"udp"}) {
                                $" && udp.dst == ${port}"
                            } else {
                                $" && tcp.dst == ${port}"
                            } in
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, STATEFUL),
                            .priority         = 120,
                            .__match          = __match2,
                            .actions          = $"ct_lb(${vip_val});",
                            .external_ids     = map_empty())
                    } else {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, STATEFUL),
                            .priority         = 110,
                            .__match          = __match,
                            .actions          = $"ct_lb(${vip_val});",
                            .external_ids     = map_empty())
                    }
                }
            }
        }
    }
}


/* Logical switch ingress table 0: ingress port security - L2 (priority 50)
                  ingress table 1: ingress port security - IP (priority 90 and 80)
                  ingress table 2: ingress port security - ND (priority 90 and 80) */
for (lsp in nb.Logical_Switch_Port if is_enabled(lsp.enabled)) {
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        var json_key = json_string_escape(lsp.name) in
        {
            for (LSPortPSEthAddresses(.lsport = lsp._uuid, .addrs = lsp_eth_addrs)) {
                for (pbinding in sb.OutProxy_Port_Binding(.logical_port = lsp.name)) {
                    var __match = if (set_is_empty(lsp.port_security)) {
                            $"inport == ${json_key}"
                        } else {
                            $"inport == ${json_key} && eth.src == {${set_space_sep(lsp_eth_addrs)}}"
                        } in
                    var actions = match (map_get(pbinding.options, "qdisc_queue_id")) {
                            None -> "next;",
                            Some{id} -> $"set_queue(${id}); next;"
                        } in
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, PORT_SEC_L2),
                        .priority         = 50,
                        .__match          = __match,
                        .actions          = actions,
                        .external_ids     = map_empty())
                }
            };
            /**
            * Build port security constraints on IPv4 and IPv6 src and dst fields
            * and add logical flows to S_SWITCH_(IN/OUT)_PORT_SEC_IP stage.
            *
            * For each port security of the logical port, following
            * logical flows are added
            *   - If the port security has IPv4 addresses,
            *     - Priority 90 flow to allow IPv4 packets for known IPv4 addresses
            *
            *   - If the port security has IPv6 addresses,
            *     - Priority 90 flow to allow IPv6 packets for known IPv6 addresses
            *
            *   - If the port security has IPv4 addresses or IPv6 addresses or both
            *     - Priority 80 flow to drop all IPv4 and IPv6 traffic
            */
            for (LSPortPSAddresses(.lsport = lsp._uuid, .ps_addrs = ps)
                 if vec_len(ps.ipv4_addrs) > 64'd0 or vec_len(ps.ipv6_addrs) > 64'd0)
            {
                if (vec_len(ps.ipv4_addrs) > 64'd0) {
                    var dhcp_match = $"inport == ${json_key}"             ++
                                     $" && eth.src == ${ps.ea_s}"         ++
                                     $" && ip4.src == 0.0.0.0"            ++
                                     $" && ip4.dst == 255.255.255.255"    ++
                                     $" && udp.src == 68 && udp.dst == 67" in {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_IP),
                            .priority         = 90,
                            .__match          = dhcp_match,
                            .actions          = "next;",
                            .external_ids     = map_empty())
                    };
                    var addrs = {
                        var addrs: Vec<string> = vec_empty();
                        for (addr in ps.ipv4_addrs) {
                            /* When the netmask is applied, if the host portion is
                             * non-zero, the host can only use the specified
                             * address.  If zero, the host is allowed to use any
                             * address in the subnet.
                             */
                            vec_push(addrs,
                                     if (addr.plen == 32 or ((addr.addr & ~addr.mask) != 0)) {
                                         addr.addr_s
                                     } else {
                                         /* host portion is zero */
                                         $"${addr.network_s}/${addr.plen}"
                                     })
                        };
                        addrs
                    } in
                    var __match =
                        $"inport == ${json_key} && eth.src == ${ps.ea_s} && ip4.src == {" ++
                        string_join(addrs, ", ") ++ "}" in
                    {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_IP),
                            .priority         = 90,
                            .__match          = __match,
                            .actions          = "next;",
                            .external_ids     = map_empty())
                    }
                };
                if (vec_len(ps.ipv6_addrs) > 64'd0) {
                    var dad_match = $"inport == ${json_key}"              ++
                                    $" && eth.src == ${ps.ea_s}"  ++
                                    $" && ip6.src == ::"            ++
                                    $" && ip6.dst == ff02::/16"     ++
                                    $" && icmp6.type == {131, 135, 143}" in
                    {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_IP),
                            .priority         = 90,
                            .__match          = dad_match,
                            .actions          = "next;",
                            .external_ids     = map_empty())
                    };
                    var __match = $"inport == ${json_key} && eth.src: ${ps.ea_s}" ++
                                  build_port_security_ipv6_flow(IN, ps.ea, ps.ipv6_addrs) in
                    {
                        sb.Out_Logical_Flow(
                            .logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_IP),
                            .priority         = 90,
                            .__match          = __match,
                            .actions          = "next;",
                            .external_ids     = map_empty())
                    }
                };
                var __match = $"inport == ${json_key} && eth.src == ${ps.ea_s} && ip" in
                {
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, PORT_SEC_IP),
                        .priority         = 80,
                        .__match          = __match,
                        .actions          = "drop;",
                        .external_ids     = map_empty())
                }
            };
            /**
             * Build port security constraints on ARP and IPv6 ND fields
             * and add logical flows to S_SWITCH_IN_PORT_SEC_ND stage.
             *
             * For each port security of the logical port, following
             * logical flows are added
             *   - If the port security has no IP (both IPv4 and IPv6) or
             *     if it has IPv4 address(es)
             *      - Priority 90 flow to allow ARP packets for known MAC addresses
             *        in the eth.src and arp.spa fields. If the port security
             *        has IPv4 addresses, allow known IPv4 addresses in the arp.tpa field.
             *
             *   - If the port security has no IP (both IPv4 and IPv6) or
             *     if it has IPv6 address(es)
             *     - Priority 90 flow to allow IPv6 ND packets for known MAC addresses
             *       in the eth.src and nd.sll/nd.tll fields. If the port security
             *       has IPv6 addresses, allow known IPv6 addresses in the nd.target field
             *       for IPv6 Neighbor Advertisement packet.
             *
             *   - Priority 80 flow to drop ARP and IPv6 ND packets.
             */
            for (LSPortPSAddresses(.lsport = lsp._uuid, .ps_addrs = ps))
            {
                var no_ip = vec_is_empty(ps.ipv4_addrs) and vec_is_empty(ps.ipv6_addrs) in
                {
                    if (not vec_is_empty(ps.ipv4_addrs) or no_ip) {
                        var __match: string = {
                            var prefix = $"inport == ${json_key} && eth.src == ${ps.ea_s} && arp.sha == ${ps.ea_s}";
                            if (not vec_is_empty(ps.ipv4_addrs)) {
                                var spas: Vec<string> = vec_empty();
                                for (addr in ps.ipv4_addrs) {
                                    /* When the netmask is applied, if the host portion is
                                     * non-zero, the host can only use the specified
                                     * address in the arp.spa.  If zero, the host is allowed
                                     * to use any address in the subnet. */
                                    if (addr.plen == 32 or (addr.addr & ~addr.mask) != 0) {
                                        vec_push(spas, addr.addr_s)
                                    } else {
                                        vec_push(spas, $"${addr.network_s}/${addr.plen}")
                                    }
                                };
                                prefix ++ $" && arp.spa == {${string_join(spas, \", \")}}"
                            } else {
                                prefix
                            }
                        } in {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = "ingress",
                                .table_id         = switch_stage(IN, PORT_SEC_ND),
                                .priority         = 90,
                                .__match          = __match,
                                .actions          = "next;",
                                .external_ids     = map_empty())
                        }
                    };
                    if (not vec_is_empty(ps.ipv6_addrs) or no_ip) {
                        var __match = $"inport == ${json_key} && eth.src == ${ps.ea_s}" ++
                                      build_port_security_ipv6_nd_flow(ps.ea, ps.ipv6_addrs) in
                        {
                            sb.Out_Logical_Flow(
                                .logical_datapath = lsname,
                                .pipeline         = "ingress",
                                .table_id         = switch_stage(IN, PORT_SEC_ND),
                                .priority         = 90,
                                .__match          = __match,
                                .actions          = "next;",
                                .external_ids     = map_empty())
                        }
                    };
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, PORT_SEC_ND),
                        .priority         = 80,
                        .__match          = $"inport == ${json_key} && (arp || nd)",
                        .actions          = "drop;",
                        .external_ids     = map_empty())
                }
            }
        }
    }
}

/* Ingress table 1 and 2: Port security - IP and ND, by default goto next.
 * (priority 0)*/
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_ND),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty());

        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, PORT_SEC_IP),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty())
    }
}

/* Ingress table 11: ARP/ND responder, skip requests coming from localnet
 * and vtep ports. (priority 100); see ovn-northd.8.xml for the
 * rationale. */
for (lsp in nb.Logical_Switch_Port if is_enabled(lsp.enabled)) {
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        if (lsp.__type == "localnet" or lsp.__type == "vtep") {
            sb.Out_Logical_Flow(.logical_datapath = lsname,
                                .pipeline         = "ingress",
                                .table_id         = switch_stage(IN, ARP_ND_RSP),
                                .priority         = 100,
                                .__match          = $"inport == ${json_string_escape(lsp.name)}",
                                .actions          = "next;",
                                .external_ids     = map_empty())
        }
    }
}

function lsp_is_up(lsp: nb.Logical_Switch_Port): bool = {
    set_nth(lsp.up, 0) != Some{false}
}

/* Ingress table 11: ARP/ND responder, reply for known IPs.
 * (priority 50). */
for (lsp in nb.Logical_Switch_Port if is_enabled(lsp.enabled)) {
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        var json_key = json_string_escape(lsp.name) in
        {
            /*
             * Add ARP/ND reply flows if either the
             *  - port is up or
             *  - port type is router or
             *  - port type is localport
             */
            if (lsp_is_up(lsp) or lsp.__type == "router" or lsp.__type == "localport") {
                for (LSPortIPv4Address(.lsport = lsp._uuid, .ea_s = ea_s, .addr = addr))
                {
                    var __match = $"arp.tpa == ${addr.addr_s} && arp.op == 1" in
                    var actions = $"eth.dst = eth.src; "            ++
                                  $"eth.src = ${ea_s}; "            ++
                                  $"arp.op = 2; /* ARP reply */ "   ++
                                  $"arp.tha = arp.sha; "            ++
                                  $"arp.sha = ${ea_s}; "            ++
                                  $"arp.tpa = arp.spa; "            ++
                                  $"arp.spa = addr.addr_s; "        ++
                                  $"outport = inport; "             ++
                                  $"flags.loopback = 1; "           ++
                                  $"output;" in
                    {
                        sb.Out_Logical_Flow(.logical_datapath = lsname,
                                            .pipeline         = "ingress",
                                            .table_id         = switch_stage(IN, ARP_ND_RSP),
                                            .priority         = 50,
                                            .__match          = __match,
                                            .actions          = actions,
                                            .external_ids     = map_empty());

                        /* Do not reply to an ARP request from the port that owns the
                         * address (otherwise a DHCP client that ARPs to check for a
                         * duplicate address will fail).  Instead, forward it the usual
                         * way.
                         *
                         * (Another alternative would be to simply drop the packet.  If
                         * everything is working as it is configured, then this would
                         * produce equivalent results, since no one should reply to the
                         * request.  But ARPing for one's own IP address is intended to
                         * detect situations where the network is not working as
                         * configured, so dropping the request would frustrate that
                         * intent.) */
                        sb.Out_Logical_Flow(.logical_datapath = lsname,
                                            .pipeline         = "ingress",
                                            .table_id         = switch_stage(IN, ARP_ND_RSP),
                                            .priority         = 100,
                                            .__match          = __match ++ $" && inport == ${json_key}",
                                            .actions          = "next;",
                                            .external_ids     = map_empty())
                    }
                };

                /* For ND solicitations, we need to listen for both the
                 * unicast IPv6 address and its all-nodes multicast address,
                 * but always respond with the unicast IPv6 address. */
                for (LSPortIPv6Address(.lsport = lsp._uuid, .ea_s = ea_s, .addr = addr))
                {
                    var __match = $"nd_ns && ip6.dst == {${addr.addr_s}, ${addr.sn_addr_s}} && nd.target == ${addr.addr_s}" in
                    var actions = $"${if (lsp.__type == \"router\") \"nd_na_router\" else \"nd_na\"} { "    ++
                                  $"eth.src = ${ea_s}; "                                                    ++
                                  $"ip6.src = ${addr.addr_s}; "                                             ++
                                  $"nd.target = ${addr.addr_s}; "                                           ++
                                  $"nd.tll = ${ea_s}; "                                                     ++
                                  "outport = inport; "                                                      ++
                                  "flags.loopback = 1; "                                                    ++
                                  "output; "                                                                ++
                                  "};" in
                    {
                        sb.Out_Logical_Flow(.logical_datapath = lsname,
                                            .pipeline         = "ingress",
                                            .table_id         = switch_stage(IN, ARP_ND_RSP),
                                            .priority         = 50,
                                            .__match          = __match,
                                            .actions          = actions,
                                            .external_ids     = map_empty());

                        /* Do not reply to a solicitation from the port that owns the
                         * address (otherwise DAD detection will fail). */
                        sb.Out_Logical_Flow(.logical_datapath = lsname,
                                            .pipeline         = "ingress",
                                            .table_id         = switch_stage(IN, ARP_ND_RSP),
                                            .priority         = 100,
                                            .__match          = __match ++ $" && inport == ${json_key}",
                                            .actions          = actions,
                                            .external_ids     = map_empty())
                    }
                }
            }
        }
    }
}

/* Ingress table 11: ARP/ND responder, by default goto next.
 * (priority 0)*/
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, ARP_ND_RSP),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty())
    }
}

function build_dhcpv4_action(
    lsp_json_key: string,
    dhcpv4_options: nb.DHCP_Options,
    offer_ip: ovs_be32) : Option<(string, string, string)> =
{
    match (ip_parse_masked(dhcpv4_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            None
        },
        Right{(var host_ip, var mask)} -> {
            if (((offer_ip ^ host_ip) & mask) != 0) {
               /* the offer ip of the logical port doesn't belong to the cidr
                * defined in the DHCPv4 options.
                */
                None
            } else {
                match ((map_get(dhcpv4_options.options, "server_id"),
                        map_get(dhcpv4_options.options, "server_mac"),
                        map_get(dhcpv4_options.options, "lease_time")))
                {
                    (Some{var server_ip}, Some{var server_mac}, Some{var lease_time}) -> {
                        var options_map = dhcpv4_options.options;

                        /* server_mac is not DHCPv4 option, delete it from the smap. */
                        map_remove(options_map, "server_mac");
                        map_insert(options_map, "netmask", ip_fmt(mask));

                        /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                         * options on different architectures (big or little endian, SSE4.2) */
                        var options: Vec<string> = vec_empty();
                        for (node in options_map) {
                            (var k, var v) = node;
                            vec_push(options, $"${k} = ${v}")
                        };
                        var options_action = $"${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcp_opts(offerip = ${ip_fmt(offer_ip)}, " ++
                                             string_join(options, ", ") ++ "); next;";
                        var response_action = $"eth.dst = eth.src; eth.src = ${server_mac}; "                           ++
                                              $"ip4.dst = ${ip_fmt(offer_ip)}; ip4.src = ${server_ip}; udp.src = 67; "  ++
                                              "udp.dst = 68; outport = inport; flags.loopback = 1; "                    ++
                                              "output;";

                        var ipv4_addr_match = $"ip4.src == ${ip_fmt(offer_ip)} && ip4.dst == {${server_ip}, 255.255.255.255}";
                        Some{(options_action, response_action, ipv4_addr_match)}
                    },
                    _ -> {
                        /* "server_id", "server_mac" and "lease_time" should be
                         * present in the dhcp_options. */
                        //static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);
                        warn($"Required DHCPv4 options not defined for lport - ${lsp_json_key}");
                        None
                    }
                }
            }
        }
    }
}

function map_get_bool_def(m: Map<string, string>, k: string, def: bool): bool = {
    match (map_get(m, k)) {
        None -> def,
        Some{x} -> {
            if (def) {
                str_to_lower(x) != "false"
            } else {
                str_to_lower(x) == "true"
            }
        }
    }
}

function build_dhcpv6_action(
    lsp_json_key: string,
    dhcpv6_options: nb.DHCP_Options,
    offer_ip: in6_addr): Option<(string, string)> =
{
    match (ipv6_parse_masked(dhcpv6_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            //warn($"cidr is invalid - ${err}");
            None
        },
        Right{(var host_ip, var mask)} -> {
            var ip6_mask: in6_addr = ipv6_addr_bitxor(offer_ip, host_ip);
            ip6_mask = ipv6_addr_bitand(ip6_mask, mask);
            if (not ipv6_mask_is_any(ip6_mask)) {
                /* offer_ip doesn't belongs to the cidr defined in lport's DHCPv6
                 * options.*/
                //warn($"ip does not belong to cidr");
                None
            } else {
                /* "server_id" should be the MAC address. */
                match (map_get(dhcpv6_options.options, "server_id")) {
                    None -> {
                        warn($"server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                        None
                    },
                    Some{server_mac} -> {
                        match (eth_addr_from_string(server_mac)) {
                            None -> {
                                warn($"server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                                None
                            },
                            Some{ea} -> {
                                /* Get the link local IP of the DHCPv6 server from the server MAC. */
                                var server_ip = ipv6_string_mapped(in6_generate_lla(ea));
                                var ia_addr = ipv6_string_mapped(offer_ip);
                                var options: Vec<string> = vec_empty();

                                /* Check whether the dhcpv6 options should be configured as stateful.
                                 * Only reply with ia_addr option for dhcpv6 stateful address mode. */
                                if (map_get_bool_def(dhcpv6_options.options, "dhcpv6_stateless", false) == false) {
                                    vec_push(options, $"ia_addr = ${ia_addr}")
                                } else ();

                                /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                                 * options on different architectures (big or little endian, SSE4.2) */
                                // FIXME: enumerate map in ascending order of keys. Is this good enough?
                                for (node in dhcpv6_options.options) {
                                    (var k, var v) = node;
                                    if (k != "dhcpv6_stateless") {
                                        vec_push(options, $"${k} = ${v}")
                                    } else ()
                                };

                                var options_action = $"${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcpv6_opts(" ++
                                                     string_join(options, ", ")                         ++
                                                     "); next;";
                                var response_action = $"eth.dst = eth.src; eth.src = ${server_mac}; "               ++
                                                      $"ip6.dst = ip6.src; ip6.src = ${server_ip}; udp.src = 547; " ++
                                                       "udp.dst = 546; outport = inport; flags.loopback = 1; "
                                                       "output;";
                                Some{(options_action, response_action)}
                            }
                        }
                    }
                }
            }
        }
    }
}


/* Logical switch ingress table 12 and 13: DHCP options and response
 * priority 100 flows. */
for (lsp in nb.Logical_Switch_Port
         /* Don't add the DHCP flows if the port is not enabled or if the
          * port is a router port. */
         if is_enabled(lsp.enabled) and lsp.__type != "router")
{
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        var json_key = json_string_escape(lsp.name) in
        {
            /* DHCPv4 options enabled for this port */
            Some{var dhcpv4_options_uuid} = set_nth(lsp.dhcpv4_options, 0) in
            {
                for (dhcpv4_options in nb.DHCP_Options(._uuid = dhcpv4_options_uuid)) {
                    for (LSPortIPv4Address(.lsport = lsp._uuid, .ea_s = ea_s, .addr = addr)) {
                        Some{(var options_action, var response_action, var ipv4_addr_match)} =
                            build_dhcpv4_action(json_key, dhcpv4_options, addr.addr) in
                        {
                            var __match = $"inport == ${json_key} && eth.src == ${ea_s} && "     ++
                                          "ip4.src == 0.0.0.0 && ip4.dst == 255.255.255.255 && " ++
                                          "udp.src == 68 && udp.dst == 67" in
                            sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                .pipeline         = "ingress",
                                                .table_id         = switch_stage(IN, DHCP_OPTIONS),
                                                .priority         = 100,
                                                .__match          = __match,
                                                .actions          = options_action,
                                                .external_ids     = map_empty());

                            /* Allow ip4.src = OFFER_IP and
                             * ip4.dst = {SERVER_IP, 255.255.255.255} for the below
                             * cases
                             *  -  When the client wants to renew the IP by sending
                             *     the DHCPREQUEST to the server ip.
                             *  -  When the client wants to renew the IP by
                             *     broadcasting the DHCPREQUEST.
                             */
                            var __match = $"inport == ${json_key} && eth.src == ${ea_s} && " ++
                                          $"${ipv4_addr_match} && udp.src == 68 && udp.dst == 67" in
                            sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                .pipeline         = "ingress",
                                                .table_id         = switch_stage(IN, DHCP_OPTIONS),
                                                .priority         = 100,
                                                .__match          = __match,
                                                .actions          = options_action,
                                                .external_ids     = map_empty());

                            /* If REGBIT_DHCP_OPTS_RESULT is set, it means the
                             * put_dhcp_opts action  is successful. */
                            var __match = $"inport == ${json_key} && eth.src == ${ea_s} && " ++
                                          "ip4 && udp.src == 68 && udp.dst == 67 && "        ++
                                          rEGBIT_DHCP_OPTS_RESULT() in
                            sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                .pipeline         = "ingress",
                                                .table_id         = switch_stage(IN, DHCP_RESPONSE),
                                                .priority         = 100,
                                                .__match          = __match,
                                                .actions          = response_action,
                                                .external_ids     = map_empty())
                            // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                            // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this breaks
                            // by computing an aggregate that returns the first element of a group.
                            //break;
                        }
                    }
                }
            };

            /* DHCPv6 options enabled for this port */
            Some{var dhcpv6_options_uuid} = set_nth(lsp.dhcpv6_options, 0) in
            {
                for (dhcpv6_options in nb.DHCP_Options(._uuid = dhcpv6_options_uuid)) {
                    for (LSPortIPv6Address(.lsport = lsp._uuid, .ea_s = ea_s, .addr = addr)) {
                        Some{(var options_action, var response_action)} =
                            build_dhcpv6_action(json_key, dhcpv6_options, addr.addr) in
                        {
                            var __match = $"inport == ${json_key} && eth.src == ${ea_s}"    ++
                                          " && ip6.dst == ff02::1:2 && udp.src == 546 &&"   ++
                                          " udp.dst == 547" in
                            {
                                sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                    .pipeline         = "ingress",
                                                    .table_id         = switch_stage(IN, DHCP_OPTIONS),
                                                    .priority         = 100,
                                                    .__match          = __match,
                                                    .actions          = options_action,
                                                    .external_ids     = map_empty());

                                /* If REGBIT_DHCP_OPTS_RESULT is set to 1, it means the
                                 * put_dhcpv6_opts action is successful */
                                sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                    .pipeline         = "ingress",
                                                    .table_id         = switch_stage(IN, DHCP_RESPONSE),
                                                    .priority         = 100,
                                                    .__match          = __match ++ $" && ${rEGBIT_DHCP_OPTS_RESULT()}",
                                                    .actions          = response_action,
                                                    .external_ids     = map_empty())
                                // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                                // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this breaks
                                // by computing an aggregate that returns the first element of a group.
                                //break;
                            }
                        }
                    }
                }
            }
        }
    }
}



relation LSHasDNSRecords(ls: uuid)

LSHasDNSRecords(ls) :-
    LogicalSwitchDNS(ls, dns),
    nb.DNS(._uuid = dns).

/* Logical switch ingress table 14 and 15: DNS lookup and response
 * priority 100 flows.
 */
for (LSHasDNSRecords(ls))
{
    var lsname = uuid2str(ls) in
    {
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DNS_RESPONSE),
                            .priority         = 100,
                            .__match          = "udp.dst == 53",
                            .actions          = $"${rEGBIT_DNS_LOOKUP_RESULT()} = dns_lookup(); next;",
                            .external_ids     = map_empty());

        var action = "eth.dst <-> eth.src; ip4.src <-> ip4.dst; "           ++
                     "udp.dst = udp.src; udp.src = 53; outport = inport; "  ++
                     "flags.loopback = 1; output;" in
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DNS_RESPONSE),
                            .priority         = 100,
                            .__match          = $"udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
                            .actions          = action,
                            .external_ids     = map_empty());

        var action = "eth.dst <-> eth.src; ip6.src <-> ip6.dst; "           ++
                     "udp.dst = udp.src; udp.src = 53; outport = inport; "  ++
                     "flags.loopback = 1; output;" in
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DNS_RESPONSE),
                            .priority         = 100,
                            .__match          = $"udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
                            .actions          = action,
                            .external_ids     = map_empty())
    }
}

/* Ingress table 12 and 13: DHCP options and response, by default goto
 * next. (priority 0).
 * Ingress table 14 and 15: DNS lookup and response, by default goto next.
 * (priority 0).*/
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DHCP_OPTIONS),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty());

        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DHCP_RESPONSE),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty());

        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DNS_LOOKUP),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty());

        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "ingress",
                            .table_id         = switch_stage(IN, DNS_RESPONSE),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = "next;",
                            .external_ids     = map_empty())
    }
}


/* Ingress table 16: Destination lookup, broadcast and multicast handling
 * (priority 100). */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in
    sb.Out_Logical_Flow(.logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, L2_LKUP),
                        .priority         = 100,
                        .__match          = "eth.mcast",
                        .actions          = $"outport = \"${mC_FLOOD()}\"; output;",
                        .external_ids     = map_empty())
}

/*
relation LSPortEthAddress(lsp: uuid, ea: eth_addr)
LSPortEthAddress(lsp, ea) :-
    nb.Logical_Switch_Port(._uuid = lsp, .addresses = addresses),
    var address = FlatMap(addresses),
    Some{var ea} = scan_eth_addr(address).
LSPortEthAddress(lsp, ea) :-
    nb.Logical_Switch_Port(._uuid = lsp, .dynamic_addresses = dyn_addresses, .addresses = addresses),
    var address = FlatMap(dyn_addresses),
    Some{var ea} = scan_eth_addr(address).
*/

relation LogicalRouterNAT(lr: uuid, nat: nb.NAT)

LogicalRouterNAT(lr, nat) :-
    nb.Logical_Router(._uuid = lr, .nat = nats),
    var nat_uuid = FlatMap(nats),
    nat in nb.NAT(._uuid = nat_uuid).

relation LogicalRouterSNATExternalIPs(lr: uuid, external_ips: Set<string>)

LogicalRouterSNATExternalIPs(lr, external_ips) :-
    LogicalRouterNAT(lr, nb.NAT{.__type = "snat", .external_ip = external_ip}),
    var external_ips = Aggregate((lr), group2set(external_ip)).

LogicalRouterSNATExternalIPs(lr, set_empty()) :-
    nb.Logical_Router(._uuid = lr),
    not LogicalRouterNAT(lr, nb.NAT{.__type = "snat"}).

/* Ingress table 16: Destination lookup, unicast handling (priority 50), */
for (lsp in nb.Logical_Switch_Port)
{
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        var json_key = json_string_escape(lsp.name) in {
            // FIXME: for dynamic addresses, native imlementation first checks is_dynamic_lsp_address(lsp.address)
            // before looking at lsp.dynamic_addresses. Is it possible that dynamic_addresses are not empty, but
            // there is no dynamic address in lsp.addresses?
            for (LSPortAddresses(.lsport = lsp._uuid, .addrs = addrs)) {
                sb.Out_Logical_Flow(.logical_datapath = lsname,
                                    .pipeline         = "ingress",
                                    .table_id         = switch_stage(IN, L2_LKUP),
                                    .priority         = 50,
                                    .__match          = $"eth.dst == ${addrs.ea}",
                                    .actions          = $"outport = ${json_key}; output;",
                                    .external_ids     = map_empty())
            };
            if (set_contains(lsp.addresses, "router"))
            {
                Some{var lrport_name} = map_get(lsp.options, "router-port") in
                for(nb.Logical_Router_Port(.name = lrport_name, ._uuid = lrport_uuid, .mac = mac_str)) {
                        Some{var mac} = scan_eth_addr(mac_str) in {
                        for (LogicalPortRouter(lrport_uuid, lr_uuid)) {
                            for (RouterPortIsRedirect(lrport_uuid, is_redirect)) {
                                var __match = if (is_redirect) {
                                    /* The destination lookup flow for the router's
                                     * distributed gateway port MAC address should only be
                                     * programmed on the "redirect-chassis". */
                                    $"eth.dst == ${mac} && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrport_name))})"
                                } else {
                                    $"eth.dst == ${mac}"
                                } in
                                sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                    .pipeline         = "ingress",
                                                    .table_id         = switch_stage(IN, L2_LKUP),
                                                    .priority         = 50,
                                                    .__match          = __match,
                                                    .actions          = $"outport = ${json_key}; output;",
                                                    .external_ids     = map_empty());

                                /* Add ethernet addresses specified in NAT rules on
                                 * distributed logical routers. */
                                if (is_redirect) {
                                    for (LogicalRouterNAT(.lr = lr_uuid, .nat = nat)) {
                                        if (nat.__type == "dnat_and_snat") {
                                            Some{var lport} = set_nth(nat.logical_port, 0) in
                                            Some{var emac} = set_nth(nat.external_mac, 0) in
                                            Some{var nat_mac} = eth_addr_from_string(emac) in
                                            var __match = $"eth.dst == ${nat_mac} && is_chassis_resident(\"${lport}\")" in
                                            sb.Out_Logical_Flow(.logical_datapath = lsname,
                                                                .pipeline         = "ingress",
                                                                .table_id         = switch_stage(IN, L2_LKUP),
                                                                .priority         = 50,
                                                                .__match          = __match,
                                                                .actions          = $"outport = ${json_key}; output;",
                                                                .external_ids     = map_empty())
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
// FIXME: do we care about this?
/*        } else {
            static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 1);

            VLOG_INFO_RL(&rl,
                         "%s: invalid syntax '%s' in addresses column",
                         op->nbsp->name, op->nbsp->addresses[i]);
        }*/
    }
}

/* Ingress table 16: Destination lookup for unknown MACs (priority 0). */
for (LogicalSwitchUnknownPorts(.ls = ls_uuid)) {
    var lsname = uuid2str(ls_uuid) in
    sb.Out_Logical_Flow(.logical_datapath = lsname,
                        .pipeline         = "ingress",
                        .table_id         = switch_stage(IN, L2_LKUP),
                        .priority         = 0,
                        .__match          = "1",
                        .actions          = $"outport = \"${mC_UNKNOWN()}\"; output;",
                        .external_ids     = map_empty())
}

/* Egress tables 8: Egress port security - IP (priority 0)
 * Egress table 9: Egress port security L2 - multicast/broadcast (priority 100). */
for (ls in nb.Logical_Switch) {
    var lsname = uuid2str(ls._uuid) in {
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "egress",
                            .table_id         = switch_stage(OUT, PORT_SEC_IP),
                            .priority         = 0,
                            .__match          = "1",
                            .actions          = $"next;",
                            .external_ids     = map_empty());
        sb.Out_Logical_Flow(.logical_datapath = lsname,
                            .pipeline         = "egress",
                            .table_id         = switch_stage(OUT, PORT_SEC_L2),
                            .priority         = 100,
                            .__match          = "eth.mcast",
                            .actions          = $"output;",
                            .external_ids     = map_empty())
    }
}

/* Egress table 8: Egress port security - IP (priorities 90 and 80)
 * if port security enabled.
 *
 * Egress table 9: Egress port security - L2 (priorities 50 and 150).
 *
 * Priority 50 rules implement port security for enabled logical port.
 *
 * Priority 150 rules drop packets to disabled logical ports, so that they
 * don't even receive multicast or broadcast packets. */
for (lsp in nb.Logical_Switch_Port)
{
    for (lps in LogicalPortSwitch(.lport = lsp._uuid)) {
        var lsname = uuid2str(lps.lswitch) in
        var json_key = json_string_escape(lsp.name) in
        {
            if (is_enabled(lsp.enabled)) {
                for (LSPortPSEthAddresses(.lsport = lsp._uuid, .addrs = lsp_eth_addrs)) {
                    var __match = $"outport == ${json_key} && eth.dst = {${set_space_sep(lsp_eth_addrs)}}" in
                    sb.Out_Logical_Flow(.logical_datapath = lsname,
                                        .pipeline         = "egress",
                                        .table_id         = switch_stage(OUT, PORT_SEC_L2),
                                        .priority         = 50,
                                        .__match          = __match,
                                        .actions          = $"output;",
                                        .external_ids     = map_empty())
                }
            } else {
                sb.Out_Logical_Flow(.logical_datapath = lsname,
                                    .pipeline         = "egress",
                                    .table_id         = switch_stage(OUT, PORT_SEC_L2),
                                    .priority         = 150,
                                    .__match          = $"outport == ${json_key}",
                                    .actions          = $"drop;",
                                    .external_ids     = map_empty())
            };
            for (LSPortPSAddresses(.lsport = lsp._uuid, .ps_addrs = ps)
                 if vec_len(ps.ipv4_addrs) > 64'd0 or vec_len(ps.ipv6_addrs) > 64'd0)
            {
                if (vec_len(ps.ipv4_addrs) > 64'd0) {
                    var addrs = {
                        var addrs: Vec<string> = vec_empty();
                        for (addr in ps.ipv4_addrs) {
                            /* When the netmask is applied, if the host portion is
                             * non-zero, the host can only use the specified
                             * address.  If zero, the host is allowed to use any
                             * address in the subnet.
                             */
                            vec_push(addrs,
                                     if (addr.plen == 32 or ((addr.addr & ~addr.mask) != 0)) {
                                         addr.addr_s ++
                                            if (addr.plen != 32) { $", ${addr.bcast_s}" } else { "" }
                                     } else {
                                         /* host portion is zero */
                                         $"${addr.network_s}/${addr.plen}"
                                     })
                        };
                        addrs
                    } in
                    var __match =
                        $"outport == ${json_key} && eth.dst == ${ps.ea_s} && ip4.dst == {255.255.255.255, 224.0.0.0/4, " ++
                        string_join(addrs, ", ") ++ "}" in
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, PORT_SEC_IP),
                        .priority         = 90,
                        .__match          = __match,
                        .actions          = "next;",
                        .external_ids     = map_empty())
                };
                if (vec_len(ps.ipv6_addrs) > 64'd0) {
                    var __match = $"outport == ${json_key} && eth.dst: ${ps.ea_s}" ++
                                  build_port_security_ipv6_flow(OUT, ps.ea, ps.ipv6_addrs) in
                    sb.Out_Logical_Flow(
                        .logical_datapath = lsname,
                        .pipeline         = "egress",
                        .table_id         = switch_stage(OUT, PORT_SEC_IP),
                        .priority         = 90,
                        .__match          = __match,
                        .actions          = "next;",
                        .external_ids     = map_empty())
                };
                var __match = $"outport == ${json_key} && eth.dst == ${ps.ea_s} && ip" in
                sb.Out_Logical_Flow(
                    .logical_datapath = lsname,
                    .pipeline         = "egress",
                    .table_id         = switch_stage(OUT, PORT_SEC_IP),
                    .priority         = 80,
                    .__match          = __match,
                    .actions          = "drop;",
                    .external_ids     = map_empty())
            }
        }
    }
}


/* Logical router ingress table 0: Admission control framework. */
for (lr in nb.Logical_Router) {
    var lrname = uuid2str(lr._uuid) in {
        /* Logical VLANs not supported.
         * Broadcast/multicast source address is invalid. */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, ADMISSION),
            .priority         = 100,
            .__match          = "vlan.present || eth.src[40]",
            .actions          = "drop;",
            .external_ids     = map_empty())
    }
}

/* Logical router ingress table 0: match (priority 50). */
for (LogicalRouterPortAttrs(.lrp = lrp,
                            .json_key = json_key,
                            .networks = lrp_networks,
                            .lr_uuid = lr_uuid, .lr_name = lr_name,
                            .is_redirect = is_redirect)
    /* Drop packets from disabled logical ports (since logical flow
     * tables are default-drop). */
    if is_enabled(lrp.enabled))
{
    //if (op->derived) {
    //    /* No ingress packets should be received on a chassisredirect
    //     * port. */
    //    continue;
    //}

    sb.Out_Logical_Flow(
        .logical_datapath = lr_name,
        .pipeline         = "ingress",
        .table_id         = router_stage(IN, ADMISSION),
        .priority         = 50,
        .__match          = $"eth.mcast && inport == ${json_key}",
        .actions          = "next;",
        .external_ids     = map_empty());

    var __match =
        $"eth.dst == ${lrp_networks.ea_s} && inport == ${json_key}" ++
        if is_redirect {
            /* Traffic with eth.dst = l3dgw_port->lrp_networks.ea_s
             * should only be received on the "redirect-chassis". */
            $" && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
        } else { "" } in
    sb.Out_Logical_Flow(
        .logical_datapath = lr_name,
        .pipeline         = "ingress",
        .table_id         = router_stage(IN, ADMISSION),
        .priority         = 50,
        .__match          = __match,
        .actions          = "next;",
        .external_ids     = map_empty())
}


/* Logical router ingress table 1: IP Input. */
for (lr in nb.Logical_Router) {
    var lrname = uuid2str(lr._uuid) in {
        /* L3 admission control: drop multicast and broadcast source, localhost
         * source or destination, and zero network source or destination
         * (priority 100). */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 100,
            .__match          = "ip4.mcast || "                     ++
                                "ip4.src == 255.255.255.255 || "    ++
                                "ip4.src == 127.0.0.0/8 || "        ++
                                "ip4.dst == 127.0.0.0/8 || "        ++
                                "ip4.src == 0.0.0.0/8 || "          ++
                                "ip4.dst == 0.0.0.0/8",
            .actions          = "drop;",
            .external_ids     = map_empty());

        /* ARP reply handling.  Use ARP replies to populate the logical
         * router's ARP table. */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 90,
            .__match          = "arp.op == 2",
            .actions          = "put_arp(inport, arp.spa, arp.sha);",
            .external_ids     = map_empty());

        /* Drop Ethernet local broadcast.  By definition this traffic should
         * not be forwarded.*/
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 50,
            .__match          = "eth.bcast",
            .actions          = "drop;",
            .external_ids     = map_empty());

        /* TTL discard */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 30,
            .__match          = "ip4 && ip.ttl == {0, 1}",
            .actions          = "drop;",
            .external_ids     = map_empty());

        /* ND advertisement handling.  Use advertisements to populate
         * the logical router's ARP/ND table. */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 90,
            .__match          = "nd_na",
            .actions          = "put_nd(inport, nd.target, nd.tll);",
            .external_ids     = map_empty());

        /* Lean from neighbor solicitations that were not directed at
         * us.  (A priority-90 flow will respond to requests to us and
         * learn the sender's mac address. */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 80,
            .__match          = "nd_ns",
            .actions          = "put_nd(inport, ip6.src, nd.sll);",
            .external_ids     = map_empty());

        /* Pass other traffic not already handled to the next table for
         * routing. */
        sb.Out_Logical_Flow(
            .logical_datapath = lrname,
            .pipeline         = "ingress",
            .table_id         = router_stage(IN, IP_INPUT),
            .priority         = 0,
            .__match          = "1",
            .actions          = "next;",
            .external_ids     = map_empty())
    }
}

function format_v4_networks(networks: lport_addresses, add_bcast: bool): string =
{
    var addrs: Vec<string> = vec_empty();
    for (addr in networks.ipv4_addrs) {
        vec_push(addrs, addr.addr_s);
        if (add_bcast) {
            vec_push(addrs, addr.bcast_s)
        } else ()
    };
    if (vec_len(addrs) == 64'd1) {
        string_join(addrs , ", ")
    } else {
        "{" ++ string_join(addrs , ", ") ++ "}"
    }
}

/* The following relation is used in ARP reply flow generation to determine whether
 * the is_chassis_resident check must be added to the flow.
 */
relation AddChassisResidentCheck_(lrp: uuid, add_check: bool)

AddChassisResidentCheck_(lrp, res) :-
    LogicalRouterPortAttrs(.lrp = nb.Logical_Router_Port{._uuid = lrp, .options = options}, .lr_uuid = lr, .is_redirect = is_redirect),
    LogicalRouterHasRedirectPort(lr, true),
    SwitchRouterPeer(.lsp = peer, .lrp = lrp),
    LSPSwitchHasLocalnetPort(peer, true),
    var res = if (is_redirect) {
        /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
         * should only be sent from the "redirect-chassis", so that
         * upstream MAC learning points to the "redirect-chassis".
         * Also need to avoid generation of multiple ARP responses
         * from different chassis. */
        true
    } else {
        /* Check if the option 'reside-on-redirect-chassis'
         * is set to true on the router port. If set to true
         * and if peer's logical switch has a localnet port, it
         * means the router pipeline for the packets from
         * peer's logical switch is be run on the chassis
         * hosting the gateway port and it should reply to the
         * ARP requests for the router port IPs.
         */
        map_get_bool_def(options, "reside-on-redirect-chassis", false)
    }.


relation AddChassisResidentCheck(lrp: uuid, add_check: bool)

AddChassisResidentCheck(lrp, add_check) :-
    AddChassisResidentCheck_(lrp, add_check).

AddChassisResidentCheck(lrp, false) :-
    nb.Logical_Router_Port(._uuid = lrp),
    not AddChassisResidentCheck_(lrp, _).


function get_force_snat_ip(lr: nb.Logical_Router, key_type: string): Option<(string, ovs_be32)> =
{
    match (map_get(lr.options, key_type ++ "_force_snat_ip")) {
        None -> None,
        Some{ip_address} -> {
            match (ip_parse_masked(ip_address)) {
                Left{err} -> {
                    warn($"bad ip ${ip_address} in options of router ${uuid2str(lr._uuid)}");
                    None
                },
                Right{(ip, mask)} -> {
                    if (mask != 32'hffffffff) {
                        warn($"bad ip ${ip_address} in options of router ${uuid2str(lr._uuid)}");
                        None
                    } else {
                        Some{(ip_address, ip)}
                    }
                }
            }
        }
    }
}

/* Logical router ingress table 1: IP Input for IPv4. */
for (LogicalRouterPortAttrs(.lrp = lrp, .json_key = json_key,
                            .lr_uuid = lr_uuid, .lr_name = lr_name,
                            .networks = lrp_networks,
                            .is_redirect = is_redirect)) {
    if (not vec_is_empty(lrp_networks.ipv4_addrs)) {
        /* L3 admission control: drop packets that originate from an
         * IPv4 address owned by the router or a broadcast address
         * known to the router (priority 100). */
        var __match = "ip4.src == "                                      ++
                       format_v4_networks(lrp_networks, true)            ++
                       $" && ${rEGBIT_EGRESS_LOOPBACK()} == 0" in
        sb.Out_Logical_Flow(
                .logical_datapath = lr_name,
                .pipeline         = "ingress",
                .table_id         = router_stage(IN, IP_INPUT),
                .priority         = 100,
                .__match          = __match,
                .actions          = "drop;",
                .external_ids     = map_empty());

        /* ICMP echo reply.  These flows reply to ICMP echo requests
         * received for the router's IP address. Since packets only
         * get here as part of the logical router datapath, the inport
         * (i.e. the incoming locally attached net) does not matter.
         * The ip.ttl also does not matter (RFC1812 section 4.2.2.9) */
        var __match = "ip4.dst == "                                      ++
                      format_v4_networks(lrp_networks, false)            ++
                      " && icmp4.type == 8 && icmp4.code == 0" in
        sb.Out_Logical_Flow(
                .logical_datapath = lr_name,
                .pipeline         = "ingress",
                .table_id         = router_stage(IN, IP_INPUT),
                .priority         = 90,
                .__match          = __match,
                .actions          = "ip4.dst <-> ip4.src; " ++
                                    "ip.ttl = 255; "        ++
                                    "icmp4.type = 0; "      ++
                                    "flags.loopback = 1; "  ++
                                    "next; ",
                .external_ids     = map_empty());

        /* ICMP time exceeded */
        for (LRPortNetworksIPv4Addr(lrp._uuid, addr)) {
            sb.Out_Logical_Flow(
                    .logical_datapath = lr_name,
                    .pipeline         = "ingress",
                    .table_id         = router_stage(IN, IP_INPUT),
                    .priority         = 40,
                    .__match          = $"inport == ${json_key} && ip4 && " ++
                                        "ip.ttl == {0, 1} && !ip.later_frag",
                    .actions          = "icmp4 {"                                       ++
                                        "eth.dst <-> eth.src; "                         ++
                                        "icmp4.type = 11; /* Time exceeded */ "         ++
                                        "icmp4.code = 0; /* TTL exceeded in transit */ "++
                                        "ip4.dst = ip4.src; "                           ++
                                        $"ip4.src = ${addr.addr_s}; "                   ++
                                        "ip.ttl = 255; "                                ++
                                        "next; };",
                    .external_ids     = map_empty())
        }
    };

    /* ARP reply.  These flows reply to ARP requests for the router's own
     * IP address. */
    for (AddChassisResidentCheck(lrp._uuid, add_chassis_resident_check)) {
        for (LRPortNetworksIPv4Addr(lrp._uuid, addr)) {
            var __match =
                $"inport == ${json_key} && arp.spa == ${addr.network_s}/${addr.plen} "  ++
                $"&& arp.tpa == ${addr.addr_s}"                                         ++
                " && arp.op == 1"                                                       ++
                if (add_chassis_resident_check) {
                    $" && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
                } else "" in
            var actions =
                "put_arp(inport, arp.spa, arp.sha); "   ++
                "eth.dst = eth.src; "                   ++
                $"eth.src = ${lrp_networks.ea_s}; "     ++
                "arp.op = 2; /* ARP reply */ "          ++
                "arp.tha = arp.sha; "                   ++
                $"arp.sha = ${lrp_networks.ea_s}; "     ++
                "arp.tpa = arp.spa; "                   ++
                $"arp.spa = ${addr.addr_s}; "           ++
                $"outport = ${json_key}; "              ++
                "flags.loopback = 1; "                  ++
                "output;" in
            sb.Out_Logical_Flow(
                    .logical_datapath = lr_name,
                    .pipeline         = "ingress",
                    .table_id         = router_stage(IN, IP_INPUT),
                    .priority         = 90,
                    .__match          = __match,
                    .actions          = actions,
                    .external_ids     = map_empty())
        }
    };

    /* Learn from ARP requests that were not directed at us. A typical
     * use case is GARP request handling.  (A priority-90 flow will
     * respond to request to us and learn the sender's mac address.) */
    for (LRPortNetworksIPv4Addr(lrp._uuid, addr)) {
        var __match =
            $"inport == ${json_key} && arp.spa == ${addr.network_s}/${addr.plen}" ++
            " && arp.op == 1" ++
            if is_redirect $" && is_chassis_resident(${json_key})" else "" in
        sb.Out_Logical_Flow(
                .logical_datapath = lr_name,
                .pipeline         = "ingress",
                .table_id         = router_stage(IN, IP_INPUT),
                .priority         = 80,
                .__match          = __match,
                .actions          = "put_arp(inport, arp.spa, arp.sha);",
                .external_ids     = map_empty())
    };

    for (LogicalRouterLBVIP(lr_uuid, (vip_key, _))) {
        Some{(var ip_address, _, var addr_family)} = ip_address_and_port_from_lb_key(vip_key) in
        var __match = if (addr_family == aF_INET()) {
                $"inport == ${json_key} && arp.tpa == ${ip_address} && arp.op == 1"
            } else {
               $"inport == ${json_key} && nd_ns && nd.target == ${ip_address}"
            } in
        var actions = if (addr_family == aF_INET()) {
            "eth.dst = eth.src; "                   ++
            $"eth.src = ${lrp_networks.ea_s}; "     ++
            "arp.op = 2; /* ARP reply */ "          ++
            "arp.tha = arp.sha; "                   ++
            $"arp.sha = ${lrp_networks.ea_s}; "     ++
            "arp.tpa = arp.spa; "                   ++
            $"arp.spa = ${ip_address}; "            ++
            $"outport = ${json_key}; "              ++
            "flags.loopback = 1; "                  ++
            "output;"
        } else {
            "nd_na { "                              ++
            $"eth.src = ${lrp_networks.ea_s}; "     ++
            $"ip6.src = ${ip_address}; "            ++
            $"nd.target = ${ip_address}; "          ++
            $"nd.tll = ${lrp_networks.ea_s}; "      ++
            "outport = inport; "                    ++
            "flags.loopback = 1; "                  ++
            "output; "                              ++
            "};"
        } in
        sb.Out_Logical_Flow(
                .logical_datapath = lr_name,
                .pipeline         = "ingress",
                .table_id         = router_stage(IN, IP_INPUT),
                .priority         = 90,
                .__match          = __match,
                .actions          = actions,
                .external_ids     = map_empty())
    };

    for (LogicalRouterNAT(lr_uuid, nat) if nat.__type != "snat") {
        Some{var ip} = match (ip_parse(nat.external_ip)) {
            Some{ip} -> { Some{ip} },
            None -> {
                warn($"bad ip address ${nat.external_ip} in nat configuration " ++
                     $"for router ${uuid2str(lr_uuid)}");
                None: Option<ovs_be32>
            }
        } in
        /* ARP handling for external IP addresses.
         *
         * DNAT IP addresses are external IP addresses that need ARP
         * handling. */
        var __match = $"inport == ${json_key} && arp.tpa == ${ip_fmt(ip)} && arp.op == 1" in
        var actions = "eth.dst = eth.src; "             ++
                      "arp.op = 2; /* ARP reply */ "    ++
                      "arp.tha = arp.sha; " in
        (var __match2, var actions2) = if is_redirect {
            match ((set_nth(nat.external_mac, 0), set_nth(nat.logical_port, 0))) {
                (Some{external_mac}, Some{logical_port}) -> {
                    match (eth_addr_from_string(external_mac)) {
                        Some{mac} -> {
                            /* distributed NAT case, use nat->external_mac */
                            /* Traffic with eth.src = nat->external_mac should only be
                             * sent from the chassis where nat->logical_port is
                             * resident, so that upstream MAC learning points to the
                             * correct chassis.  Also need to avoid generation of
                             * multiple ARP responses from different chassis. */
                            ( __match ++ $" && is_chassis_resident(\"${logical_port}\")"
                            , actions ++ $"eth.src = ${mac}; arp.sha = ${mac}; ")
                        },
                        None -> {
                            ( __match ++ $" && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
                            , actions ++ $"eth.src = ${lrp_networks.ea_s}; arp.sha = ${lrp_networks.ea_s}; ")
                        }
                    }
                },
                _ -> {
                    /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
                     * should only be sent from the "redirect-chassis", so that
                     * upstream MAC learning points to the "redirect-chassis".
                     * Also need to avoid generation of multiple ARP responses
                     * from different chassis. */
                    ( __match ++ $" && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
                    , actions ++ $"eth.src = ${lrp_networks.ea_s}; arp.sha = ${lrp_networks.ea_s}; ")
                }
            }
        } else {
            ( __match
            , actions ++ $"eth.src = ${lrp_networks.ea_s}; arp.sha = ${lrp_networks.ea_s}; ")
        } in
        sb.Out_Logical_Flow(
                .logical_datapath = lr_name,
                .pipeline         = "ingress",
                .table_id         = router_stage(IN, IP_INPUT),
                .priority         = 90,
                .__match          = __match2,
                .actions          = actions2                    ++
                                    "arp.tpa = arp.spa; "       ++
                                    $"arp.spa = ${ip_fmt(ip)}; "++
                                    $"outport = ${json_key}; "  ++
                                    "flags.loopback = 1; "      ++
                                    "output;",
                .external_ids     = map_empty())
    };

    for (LogicalRouterHasRedirectPort(lr_uuid, true)) {
        for (nb.Logical_Router(._uuid = lr_uuid, .options = lr_options)
             if is_none(map_get(lr_options, "chassis")))
        {
            /* UDP/TCP port unreachable. */
            for (LRPortNetworksIPv4Addr(lrp._uuid, addr)) {
                var __match = $"ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag && udp" in
                sb.Out_Logical_Flow(
                        .logical_datapath = lr_name,
                        .pipeline         = "ingress",
                        .table_id         = router_stage(IN, IP_INPUT),
                        .priority         = 80,
                        .__match          = __match,
                        .actions          = "icmp4 {"                  ++
                                            "eth.dst <-> eth.src; "    ++
                                            "ip4.dst <-> ip4.src; "    ++
                                            "ip.ttl = 255; "           ++
                                            "icmp4.type = 3; "         ++
                                            "icmp4.code = 3; "         ++
                                            "next; };",
                        .external_ids     = map_empty());

                var __match = $"ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag && tcp" in
                sb.Out_Logical_Flow(
                        .logical_datapath = lr_name,
                        .pipeline         = "ingress",
                        .table_id         = router_stage(IN, IP_INPUT),
                        .priority         = 80,
                        .__match          = __match,
                        .actions          = "tcp_reset {"           ++
                                            "eth.dst <-> eth.src; " ++
                                            "ip4.dst <-> ip4.src; " ++
                                            "next; };",
                        .external_ids     = map_empty());

                var __match = $"ip4 && ip4.dst == ${addr.addr_s} && !ip.later_frag" in
                sb.Out_Logical_Flow(
                        .logical_datapath = lr_name,
                        .pipeline         = "ingress",
                        .table_id         = router_stage(IN, IP_INPUT),
                        .priority         = 70,
                        .__match          = __match,
                        .actions          = "icmp4 {"               ++
                                            "eth.dst <-> eth.src; " ++
                                            "ip4.dst <-> ip4.src; " ++
                                            "ip.ttl = 255; "        ++
                                            "icmp4.type = 3; "      ++
                                            "icmp4.code = 2; "      ++
                                            "next; };",
                        .external_ids     = map_empty())
            }
        }
    };

    /* A gateway router can have 2 SNAT IP addresses to force DNATed and
     * LBed traffic respectively to be SNATed.  In addition, there can be
     * a number of SNAT rules in the NAT table. */
    for (lr in nb.Logical_Router(._uuid = lr_uuid)) {
        for (LogicalRouterSNATExternalIPs(lr_uuid, external_ips)) {
            var snat_ips: Set<ovs_be32> = {
                var snat_ips: Set<ovs_be32> = set_empty();
                for (ip in external_ips) {
                    match (ip_parse(ip)) {
                        Some{snat_ip} -> set_insert(snat_ips, snat_ip),
                        None -> warn($"bad ip address ${ip} in nat configuration " ++
                                     $"for router ${uuid2str(lr_uuid)}")

                    }
                };
                match (get_force_snat_ip(lr, "dnat")) {
                    Some{(_, snat_ip)} -> set_insert(snat_ips, snat_ip),
                    None -> ()
                };
                match (get_force_snat_ip(lr, "lb")) {
                    Some{(_, snat_ip)} -> set_insert(snat_ips, snat_ip),
                    None -> ()
                };
                snat_ips
            } in
            var ips = {
                var ips: Vec<string> = vec_empty();
                for (ip in lrp_networks.ipv4_addrs) {
                    if (not set_contains(snat_ips, ip.addr)) {
                        vec_push(ips, ip.addr_s)
                    } else ()
                };
                ips
            } in
            var __match = "ip4.dst == {" ++ string_join(ips, ", ") ++ "}" in
            if (not vec_is_empty(ips)) {
                sb.Out_Logical_Flow(
                        .logical_datapath = lr_name,
                        .pipeline         = "ingress",
                        .table_id         = router_stage(IN, IP_INPUT),
                        .priority         = 60,
                        .__match          = __match,
                        .actions          = "drop;",
                        .external_ids     = map_empty())
            }
        }
    }
}

/*
 * Datapath tunnel key allocation:
 *
 * Allocates a globally unique tunnel id in the range 1...2**24-1 for
 * each Logical_Switch and Logical_Router.
 */

// all tunnel keys already in use in the Realized table
relation AllocatedTunKeys(keys: Set<integer>)

AllocatedTunKeys(keys) :-
    sb.Datapath_Binding(.tunnel_key = tunkey),
    var keys = Aggregate((), group2set(tunkey)).

// Datapath_Binding's not yet in the Realized table
relation NotYetAllocatedTunKeys(datapaths: Vec<string>)

NotYetAllocatedTunKeys(datapaths) :-
    sb.UUIDMap_Datapath_Binding(.uuid_name = datapath,
                                .id = Right{_}),
    datapath != "",
    var datapaths = Aggregate((), group2vec(datapath)).

// Perform the allocation
relation TunKeyAllocation(datapath: string, tunkey: integer)

// transfer existing allocations from the realized table
TunKeyAllocation(datapath, tunkey) :-
     sb.UUIDMap_Datapath_Binding(.uuid_name = datapath,
                                 .id = Left{uuid}),
     sb.Datapath_Binding(._uuid = uuid,
                         .tunnel_key = tunkey).

// Case 1: AllocatedTunKeys relation is not empty (i.e., contains
// a single record that stores a set of allocated keys)
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    AllocatedTunKeys(allocated),
    var allocation = FlatMap(allocate_u64(allocated, unallocated, 64'hfffffffff)),
    (var datapath, var tunkey) = allocation.

// Case 2: AllocatedTunKeys relation is empty
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    not AllocatedTunKeys(_),
    var allocation = FlatMap(allocate_u64(set_empty(), unallocated, 64'hfffffffff)),
    (var datapath, var tunkey) = allocation.

/*
 * Port id allocation:
 *
 * Port IDs in a per-datapath space in the range 1...2**15-1
 */

// all tunnel keys already in use in the Realized table
relation AllocatedPortTunKeys(datapath: string, keys: Set<integer>)

AllocatedPortTunKeys(datapath_name, keys) :-
    sb.Port_Binding(.datapath = datapath_uuid, .tunnel_key = tunkey),
    sb.UUIDMap_Datapath_Binding(datapath_name, Left{datapath_uuid}),
    var keys = Aggregate((datapath_name), group2set(tunkey)).

// Port_Binding's not yet in the Realized table
relation NotYetAllocatedPortTunKeys(datapath: string, all_logical_ids: Vec<string>)

NotYetAllocatedPortTunKeys(datapath, all_names) :-
    sb.Out_Port_Binding(.uuid_name = uuid_name, .datapath = datapath),
    sb.UUIDMap_Port_Binding(.uuid_name = uuid_name,
                            .id = Right{_}),
    var all_names = Aggregate((datapath), group2vec(uuid_name)).

// Perform the allocation
relation PortTunKeyAllocation(port: string, tunkey: integer)

// transfer existing allocations from the realized table
PortTunKeyAllocation(port, tunkey) :-
     sb.UUIDMap_Port_Binding(.uuid_name = port,
                             .id = Left{uuid}),
     sb.Port_Binding(._uuid = uuid,
                     .tunnel_key = tunkey).

// Case 1: AllocatedPortTunKeys(datapath) is not empty (i.e., contains
// a single record that stores a set of allocated keys)
PortTunKeyAllocation(port, tunkey) :-
    AllocatedPortTunKeys(datapath, allocated),
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    var allocation = FlatMap(allocate_u64(allocated, unallocated, 64'hffff)),
    (var port, var tunkey) = allocation.

// Case 2: PortAllocatedTunKeys(datapath) relation is empty
PortTunKeyAllocation(port, tunkey) :-
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    not AllocatedPortTunKeys(datapath, _),
    var allocation = FlatMap(allocate_u64(set_empty(), unallocated, 64'hffff)),
    (var port, var tunkey) = allocation.

/*
 * Queue ID allocation
 *
 * Queue IDs on a chassis, for routers that have QoS enabled, in a per-chassis
 * space in the range 1...0xf000.  It looks to me like there'd only be a small
 * number of these per chassis, and probably a small number overall, in case it
 * matters.
 *
 * Queue ID may also need to be deallocated if port loses QoS attributes
 *
 * This logic only applies to ports with chassis attribute, i.e., they must be
 * in sb.Port_Binding.
 */

function port_has_qos_params(opts: Map<string, string>): bool = {
    map_contains_key(opts, "qos_max_rate") or
    map_contains_key(opts, "qos_burst")
}


// ports in Out_Port_Binding that require queue ID on chassis
relation PortRequiresQID(port: string, chassis: uuid)

PortRequiresQID(pb.uuid_name, chassis) :-
    sb.Out_Port_Binding[pb],
    port_has_qos_params(pb.options),
    sb.UUIDMap_Port_Binding(pb.uuid_name, Left{uuid}),
    sb.Port_Binding(._uuid = uuid, .chassis = chassis_set),
    Some{var chassis} = set_nth(chassis_set, 0).

relation AggPortRequiresQID(chassis: uuid, ports: Vec<string>)

AggPortRequiresQID(chassis, ports) :-
    PortRequiresQID(port, chassis),
    var ports = Aggregate((chassis), group2vec(port)).

relation AllocatedQIDs(chassis: uuid, allocated_ids: Map<string, integer>)

AllocatedQIDs(chassis, allocated_ids) :-
    sb.Port_Binding[pb],
    Some{var chassis} = set_nth(pb.chassis, 0),
    Some{var qid_str} = map_get(pb.options, "qdisc_queue_id"),
    Some{var qid: bit<64>} = parse_dec_u64(qid_str),
    sb.UUIDMap_Port_Binding(port, Left{pb._uuid}),
    var allocated_ids = Aggregate((chassis), group2map((port, qid))).

// allocate queueue IDs to ports
relation QueueIDAllocation(port: string, qids: Option<integer>)

// None for ports that do not require a queue
QueueIDAllocation(port, None) :-
    sb.Out_Port_Binding(.uuid_name = port),
    not PortRequiresQID(port, _).

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    AllocatedQIDs(chassis, allocated_ids),
    var allocations = FlatMap(adjust_allocation_u64(allocated_ids, ports, 64'hf000)),
    (var port, var qid) = allocations.

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    not AllocatedQIDs(chassis, _),
    var allocations = FlatMap(adjust_allocation_u64(map_empty(): Map<string, integer>, ports, 64'hf000)),
    (var port, var qid) = allocations.


///*
// * IPAM (IP address management) and MACAM (MAC address management)
// *
// * IPAM generally stands for IP address management.  In non-virtualized
// * world, MAC addresses come with the hardware.  But, with virtualized
// * workloads, they need to be assigned and managed.  This function
// * does both IP address management (ipam) and MAC address management
// * (macam).
// */
//
//
///* If the switch's other_config:subnet is set, allocate new addresses for
// * ports that have the "dynamic" keyword in their addresses column.
// */
//
///* Do not allocate addresses for logical switch ports that have a peer. */
//
///* If there's more than one dynamic addresses in port->addresses, log a warning
//   and only allocate the first dynamic address */
//
//      VLOG_WARN_RL(&rl, "More than one dynamic address "
//              "configured for logical switch port '%s'",
//              nbsp->name);
//
////>> * MAC addresses suffixes in OUIs managed by OVN"s MACAM (MAC Address
////>> Management) system, in the range 1...0xfffffe.
////>> * IPv4 addresses in ranges managed by OVN's IPAM (IP Address Management)
////>> system.  The range varies depending on the size of the subnet.
////>>
////>> Are these `dynamic_addresses` in OVN_Northbound.Logical_Switch_Port`?
//
///* Returns true if specified address specifies a dynamic address,
// * supporting the following formats:
// *
// *    "dynamic":
// *        Both MAC and IP are to be allocated dynamically.
// *
// *    "xx:xx:xx:xx:xx:xx dynamic":
// *        Use specified MAC address, but allocate an IP address
// *        dynamically.
// */
///*bool
//is_dynamic_lsp_address(const char *address)
//{
//    struct eth_addr ea;
//    int n;
//    return (!strcmp(address, "dynamic")
//            || (ovs_scan(address, ETH_ADDR_SCAN_FMT" dynamic%n",
//                         ETH_ADDR_SCAN_ARGS(ea), &n) && address[n] == '\0'));
//}*/
//
//
///* Currently used MAC addresses, including:
// *
// */
//relation AllocatedTunKeys(keys: Set<integer>)
//
//AllocatedTunKeys(keys) :-
//    sb.Datapath_Binding(.tunnel_key = tunkey),
//    Aggregate((), keys = group2set(tunkey)).
//
//// Datapath_Binding's not yet in the Realized table
//relation NotYetAllocatedTunKeys(datapaths: Vec<string>)
//
//NotYetAllocatedTunKeys(datapaths) :-
//    sb.UUIDMap_Datapath_Binding(.uuid_name = datapath,
//                                .id = Right{_}),
//    datapath != "",
//    Aggregate((), datapaths = group2vec(datapath)).
//
//// Perform the allocation
//relation TunKeyAllocation(datapath: string, tunkey: integer)
//
//// transfer existing allocations from the realized table
//TunKeyAllocation(datapath, tunkey) :-
//     sb.UUIDMap_Datapath_Binding(.uuid_name = datapath,
//                                 .id = Left{uuid}),
//     sb.Datapath_Binding(._uuid = uuid,
//                         .tunnel_key = tunkey).
//
//// Case 1: AllocatedTunKeys relation is not empty (i.e., contains
//// a single record that stores a set of allocated keys)
//TunKeyAllocation(datapath, tunkey) :-
//    NotYetAllocatedTunKeys(unallocated),
//    AllocatedTunKeys(allocated),
//    var allocation = FlatMap(allocate_u64(allocated, unallocated, 64'hfffffffff)),
//    (var datapath, var tunkey) = allocation.
//
//// Case 2: AllocatedTunKeys relation is empty
//TunKeyAllocation(datapath, tunkey) :-
//    NotYetAllocatedTunKeys(unallocated),
//    not AllocatedTunKeys(_),
//    var allocation = FlatMap(allocate_u64(set_empty(), unallocated, 64'hfffffffff)),
//    (var datapath, var tunkey) = allocation.
//
